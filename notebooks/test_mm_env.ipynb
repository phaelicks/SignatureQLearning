{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run base.ipynb\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abides_gym_market_making_environment import *\n",
    "from policies import SigPolicy\n",
    "from train import train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register market making env for gym use \n",
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id=\"market-making-v0\",\n",
    "    entry_point=SubGymMarketsMarketMakingEnv_v0,\n",
    ")\n",
    "\n",
    "def generate_env(seed):\n",
    "    \"\"\"\n",
    "    generates specific environment with the parameters defined and set the seed\n",
    "    \"\"\"\n",
    "    env = gym.make(\n",
    "            \"market-making-v0\",\n",
    "            background_config=\"rmsc04\",\n",
    "            mkt_close=\"11:45:00\",\n",
    "            timestep_duration=\"10s\",\n",
    "            order_fixed_size=100,\n",
    "            first_interval=\"00:10:00\",\n",
    "            max_inventory=1000,\n",
    "            remaining_inventory_reward=-100,#penalty\n",
    "            inventory_reward_dampener=0.6,\n",
    "            damp_mode=\"asymmetric\",\n",
    "            debug_mode=False\n",
    "        )\n",
    "\n",
    "    env.seed(seed)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the environment\n",
    "env = generate_env(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0579, -0.0357,  0.0119,  0.1326,  0.1309, -0.0637, -0.0314, -0.1207,\n",
      "          0.0194,  0.0891,  0.0976, -0.0582, -0.0540, -0.1195, -0.1181,  0.0731,\n",
      "         -0.1091, -0.0710, -0.1059,  0.0315, -0.1074,  0.0472, -0.0041, -0.1051,\n",
      "          0.0046, -0.0137,  0.0452, -0.0524,  0.0935, -0.1253, -0.0627,  0.1022,\n",
      "         -0.1014,  0.0430,  0.1289, -0.1123, -0.0412, -0.0867,  0.0973, -0.1244,\n",
      "          0.1219,  0.0151,  0.1109, -0.1010, -0.0092, -0.1128, -0.0658,  0.1152,\n",
      "          0.0303,  0.1240,  0.1034, -0.1040, -0.1048, -0.0374,  0.1105, -0.0226]])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.1089, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.062150000000000004\n",
      "pnl: 0.01215\n",
      "inv reward: 0.05\n",
      "inventors: -19\n",
      "loss: tensor(0.1005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -19\n",
      "loss: tensor(0.0280, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0095\n",
      "pnl: 0\n",
      "inv reward: -0.0095\n",
      "inventors: -19\n",
      "loss: tensor(0.0084, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0096\n",
      "pnl: -0.0001\n",
      "inv reward: -0.0095\n",
      "inventors: -17\n",
      "loss: tensor(0.0070, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0618, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0085\n",
      "pnl: 0\n",
      "inv reward: 0.0085\n",
      "inventors: -17\n",
      "loss: tensor(0.0002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0425, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0085\n",
      "pnl: 0\n",
      "inv reward: 0.0085\n",
      "inventors: -17\n",
      "loss: tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0468, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0106, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0085\n",
      "pnl: 0\n",
      "inv reward: 0.0085\n",
      "inventors: -17\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0024, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0205, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -17\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0575\n",
      "pnl: 0.015\n",
      "inv reward: 0.0425\n",
      "inventors: 83\n",
      "loss: tensor(0.0204, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 83\n",
      "loss: tensor(4.7977e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.083\n",
      "pnl: 0\n",
      "inv reward: 0.083\n",
      "inventors: 83\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08505\n",
      "pnl: -0.00205\n",
      "inv reward: -0.083\n",
      "inventors: 74\n",
      "loss: tensor(0.0475, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.074\n",
      "pnl: 0\n",
      "inv reward: -0.074\n",
      "inventors: 74\n",
      "loss: tensor(0.0034, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 74\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.037\n",
      "pnl: 0\n",
      "inv reward: 0.037\n",
      "inventors: 74\n",
      "loss: tensor(0.0222, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 74\n",
      "loss: tensor(0.0575, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.037\n",
      "pnl: 0\n",
      "inv reward: 0.037\n",
      "inventors: 74\n",
      "loss: tensor(0.0010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.074\n",
      "pnl: 0\n",
      "inv reward: -0.074\n",
      "inventors: 74\n",
      "loss: tensor(0.0022, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.037\n",
      "pnl: 0\n",
      "inv reward: -0.037\n",
      "inventors: 74\n",
      "loss: tensor(0.1016, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 174\n",
      "loss: tensor(0.0143, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.174\n",
      "pnl: 0\n",
      "inv reward: -0.174\n",
      "inventors: 174\n",
      "loss: tensor(0.0245, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1305\n",
      "pnl: 0\n",
      "inv reward: -0.1305\n",
      "inventors: 174\n",
      "loss: tensor(0.1881, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.174\n",
      "pnl: 0\n",
      "inv reward: -0.174\n",
      "inventors: 174\n",
      "loss: tensor(0.2797, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0435\n",
      "pnl: 0\n",
      "inv reward: -0.0435\n",
      "inventors: 174\n",
      "loss: tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 174\n",
      "loss: tensor(0.0776, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1305\n",
      "pnl: 0\n",
      "inv reward: -0.1305\n",
      "inventors: 174\n",
      "loss: tensor(0.1564, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.522\n",
      "pnl: 0\n",
      "inv reward: -0.522\n",
      "inventors: 174\n",
      "loss: tensor(0.3056, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.087\n",
      "pnl: 0\n",
      "inv reward: -0.087\n",
      "inventors: 174\n",
      "loss: tensor(1.7422, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0435\n",
      "pnl: 0\n",
      "inv reward: -0.0435\n",
      "inventors: 174\n",
      "loss: tensor(0.0177, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0435\n",
      "pnl: 0\n",
      "inv reward: 0.0435\n",
      "inventors: 174\n",
      "loss: tensor(0.4692, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0141\n",
      "pnl: 0.0141\n",
      "inv reward: 0.0\n",
      "inventors: 127\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.03175\n",
      "pnl: 0\n",
      "inv reward: -0.03175\n",
      "inventors: 127\n",
      "loss: tensor(0.0090, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 127\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 127\n",
      "loss: tensor(0.3546, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00065\n",
      "pnl: -0.00065\n",
      "inv reward: 0.0\n",
      "inventors: 114\n",
      "loss: tensor(0.1851, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 114\n",
      "loss: tensor(0.0658, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.057\n",
      "pnl: 0\n",
      "inv reward: -0.057\n",
      "inventors: 114\n",
      "loss: tensor(0.1846, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 114\n",
      "loss: tensor(0.0777, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 114\n",
      "loss: tensor(0.1587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 114\n",
      "loss: tensor(0.0002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.114\n",
      "pnl: 0\n",
      "inv reward: -0.114\n",
      "inventors: 114\n",
      "loss: tensor(0.0002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.228\n",
      "pnl: 0\n",
      "inv reward: -0.228\n",
      "inventors: 114\n",
      "loss: tensor(0.0221, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0006\n",
      "pnl: -0.0006\n",
      "inv reward: 0.0\n",
      "inventors: 102\n",
      "loss: tensor(0.0444, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 102\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.051\n",
      "pnl: 0\n",
      "inv reward: -0.051\n",
      "inventors: 102\n",
      "loss: tensor(0.1718, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 102\n",
      "loss: tensor(0.0021, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0036\n",
      "pnl: 0.0036\n",
      "inv reward: 0.0\n",
      "inventors: 110\n",
      "loss: tensor(0.0027, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0825\n",
      "pnl: 0\n",
      "inv reward: -0.0825\n",
      "inventors: 110\n",
      "loss: tensor(0.0891, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.08360000000000001\n",
      "pnl: 0.0011\n",
      "inv reward: 0.0825\n",
      "inventors: 99\n",
      "loss: tensor(0.0882, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 99\n",
      "loss: tensor(0.0816, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0985\n",
      "pnl: 0.0005\n",
      "inv reward: -0.099\n",
      "inventors: 101\n",
      "loss: tensor(0.0186, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1765\n",
      "pnl: 0.025\n",
      "inv reward: 0.1515\n",
      "inventors: 1\n",
      "loss: tensor(0.6332, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00065\n",
      "pnl: -0.00015\n",
      "inv reward: -0.0005\n",
      "inventors: 0\n",
      "loss: tensor(0.4935, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.2547, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0538, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.7777, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.1799, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: 0\n",
      "loss: tensor(1.4333, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0491, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01375\n",
      "pnl: 0.01375\n",
      "inv reward: -0.0\n",
      "inventors: 55\n",
      "loss: tensor(0.1022, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0275\n",
      "pnl: 0\n",
      "inv reward: -0.0275\n",
      "inventors: 55\n",
      "loss: tensor(0.0295, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.012499999999999999\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.0275\n",
      "inventors: 155\n",
      "loss: tensor(0.2665, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.35250000000000004\n",
      "pnl: 0.035\n",
      "inv reward: -0.3875\n",
      "inventors: 255\n",
      "loss: tensor(0.0043, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3825\n",
      "pnl: 0\n",
      "inv reward: -0.3825\n",
      "inventors: 255\n",
      "loss: tensor(0.2198, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 255\n",
      "loss: tensor(1.0722, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.70125\n",
      "pnl: 0\n",
      "inv reward: -0.70125\n",
      "inventors: 255\n",
      "loss: tensor(1.0916, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.765\n",
      "pnl: 0\n",
      "inv reward: -0.765\n",
      "inventors: 255\n",
      "loss: tensor(0.0023, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.19125\n",
      "pnl: 0\n",
      "inv reward: 0.19125\n",
      "inventors: 255\n",
      "loss: tensor(0.1258, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.19125\n",
      "pnl: 0\n",
      "inv reward: -0.19125\n",
      "inventors: 255\n",
      "loss: tensor(0.0163, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.84875\n",
      "pnl: 0.02\n",
      "inv reward: 0.82875\n",
      "inventors: 155\n",
      "loss: tensor(2.0216, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.155\n",
      "pnl: 0\n",
      "inv reward: 0.155\n",
      "inventors: 155\n",
      "loss: tensor(0.4803, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 155\n",
      "loss: tensor(0.1450, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0008\n",
      "pnl: -0.0008\n",
      "inv reward: 0.0\n",
      "inventors: 139\n",
      "loss: tensor(0.3575, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 139\n",
      "loss: tensor(0.1411, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 139\n",
      "loss: tensor(0.0049, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0695\n",
      "pnl: 0\n",
      "inv reward: 0.0695\n",
      "inventors: 139\n",
      "loss: tensor(0.0697, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.263\n",
      "pnl: 0.015\n",
      "inv reward: -0.278\n",
      "inventors: 239\n",
      "loss: tensor(0.1037, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 239\n",
      "loss: tensor(0.5181, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1195\n",
      "pnl: 0\n",
      "inv reward: -0.1195\n",
      "inventors: 239\n",
      "loss: tensor(0.1016, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 239\n",
      "loss: tensor(0.0010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1195\n",
      "pnl: 0\n",
      "inv reward: -0.1195\n",
      "inventors: 239\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 239\n",
      "loss: tensor(0.1672, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.204\n",
      "pnl: 0.035\n",
      "inv reward: -0.239\n",
      "inventors: 339\n",
      "loss: tensor(0.2184, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08475\n",
      "pnl: 0\n",
      "inv reward: -0.08475\n",
      "inventors: 339\n",
      "loss: tensor(0.0012, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08475\n",
      "pnl: 0\n",
      "inv reward: -0.08475\n",
      "inventors: 339\n",
      "loss: tensor(0.2191, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 339\n",
      "loss: tensor(1.9733, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1695\n",
      "pnl: 0\n",
      "inv reward: 0.1695\n",
      "inventors: 339\n",
      "loss: tensor(0.3116, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 339\n",
      "loss: tensor(0.5438, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.14625000000000002\n",
      "pnl: 0.02325\n",
      "inv reward: -0.1695\n",
      "inventors: 432\n",
      "loss: tensor(0.0035, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 432\n",
      "loss: tensor(0.0062, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 432\n",
      "loss: tensor(0.0328, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.216\n",
      "pnl: 0\n",
      "inv reward: 0.216\n",
      "inventors: 432\n",
      "loss: tensor(0.0501, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.20879999999999999\n",
      "pnl: 0.0072\n",
      "inv reward: -0.216\n",
      "inventors: 480\n",
      "loss: tensor(0.0002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0024\n",
      "pnl: -0.0024\n",
      "inv reward: 0.0\n",
      "inventors: 432\n",
      "loss: tensor(3.8744, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 432\n",
      "loss: tensor(0.0007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 432\n",
      "loss: tensor(0.2539, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23099999999999998\n",
      "pnl: 0.015\n",
      "inv reward: 0.216\n",
      "inventors: 332\n",
      "loss: tensor(1.0121, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1643\n",
      "pnl: -0.0017\n",
      "inv reward: 0.166\n",
      "inventors: 298\n",
      "loss: tensor(5.0746e-05, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0745\n",
      "pnl: 0\n",
      "inv reward: -0.0745\n",
      "inventors: 298\n",
      "loss: tensor(0.0062, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2235\n",
      "pnl: 0\n",
      "inv reward: 0.2235\n",
      "inventors: 298\n",
      "loss: tensor(4.6125, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 298\n",
      "loss: tensor(1.9278, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2385\n",
      "pnl: 0.015\n",
      "inv reward: 0.2235\n",
      "inventors: 198\n",
      "loss: tensor(0.0835, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.27749999999999997\n",
      "pnl: 0.03\n",
      "inv reward: 0.2475\n",
      "inventors: 98\n",
      "loss: tensor(0.2902, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 98\n",
      "loss: tensor(0.0112, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.049\n",
      "pnl: 0\n",
      "inv reward: 0.049\n",
      "inventors: 98\n",
      "loss: tensor(0.0726, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0005\n",
      "pnl: -0.0005\n",
      "inv reward: 0.0\n",
      "inventors: 88\n",
      "loss: tensor(0.0138, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.044\n",
      "pnl: 0\n",
      "inv reward: 0.044\n",
      "inventors: 88\n",
      "loss: tensor(0.0974, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00045\n",
      "pnl: -0.00045\n",
      "inv reward: 0.0\n",
      "inventors: 79\n",
      "loss: tensor(0.2124, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 79\n",
      "loss: tensor(0.0427, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0395\n",
      "pnl: 0\n",
      "inv reward: -0.0395\n",
      "inventors: 79\n",
      "loss: tensor(0.0171, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0004\n",
      "pnl: -0.0004\n",
      "inv reward: 0.0\n",
      "inventors: 71\n",
      "loss: tensor(0.0773, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0355\n",
      "pnl: 0\n",
      "inv reward: -0.0355\n",
      "inventors: 71\n",
      "loss: tensor(0.0002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.05109999999999999\n",
      "pnl: 0.0156\n",
      "inv reward: 0.0355\n",
      "inventors: 167\n",
      "loss: tensor(2.9552e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3725\n",
      "pnl: 0.045\n",
      "inv reward: -0.4175\n",
      "inventors: 267\n",
      "loss: tensor(0.0248, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 267\n",
      "loss: tensor(0.0063, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.267\n",
      "pnl: 0\n",
      "inv reward: -0.267\n",
      "inventors: 267\n",
      "loss: tensor(1.8897e-07, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 267\n",
      "loss: tensor(0.1218, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.29200000000000004\n",
      "pnl: 0.025\n",
      "inv reward: 0.267\n",
      "inventors: 167\n",
      "loss: tensor(0.0713, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 167\n",
      "loss: tensor(0.0536, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 267\n",
      "loss: tensor(0.1516, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.37215\n",
      "pnl: 0.038400000000000004\n",
      "inv reward: 0.33375\n",
      "inventors: 233\n",
      "loss: tensor(0.2827, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.05825\n",
      "pnl: 0\n",
      "inv reward: 0.05825\n",
      "inventors: 233\n",
      "loss: tensor(0.0061, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.268\n",
      "pnl: 0.035\n",
      "inv reward: 0.233\n",
      "inventors: 133\n",
      "loss: tensor(0.5036, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0815\n",
      "pnl: 0.015\n",
      "inv reward: 0.0665\n",
      "inventors: 33\n",
      "loss: tensor(0.0801, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.02475\n",
      "pnl: 0\n",
      "inv reward: 0.02475\n",
      "inventors: 33\n",
      "loss: tensor(0.0165, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00825\n",
      "pnl: 0\n",
      "inv reward: -0.00825\n",
      "inventors: 33\n",
      "loss: tensor(0.0270, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.033\n",
      "pnl: 0\n",
      "inv reward: 0.033\n",
      "inventors: 33\n",
      "loss: tensor(0.0131, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.09960000000000001\n",
      "pnl: 0.0006\n",
      "inv reward: 0.099\n",
      "inventors: 29\n",
      "loss: tensor(0.2786, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0651\n",
      "pnl: -0.00015\n",
      "inv reward: 0.06525\n",
      "inventors: 26\n",
      "loss: tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0195\n",
      "pnl: 0\n",
      "inv reward: 0.0195\n",
      "inventors: 26\n",
      "loss: tensor(0.0122, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.039\n",
      "pnl: 0\n",
      "inv reward: 0.039\n",
      "inventors: 26\n",
      "loss: tensor(0.5461, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0065\n",
      "pnl: 0\n",
      "inv reward: 0.0065\n",
      "inventors: 26\n",
      "loss: tensor(0.5581, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.052500000000000005\n",
      "pnl: 0.02\n",
      "inv reward: 0.0325\n",
      "inventors: -74\n",
      "loss: tensor(0.1500, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.037\n",
      "pnl: 0\n",
      "inv reward: 0.037\n",
      "inventors: -74\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.099\n",
      "pnl: 0.025\n",
      "inv reward: 0.074\n",
      "inventors: 26\n",
      "loss: tensor(0.3564, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.013\n",
      "pnl: 0\n",
      "inv reward: -0.013\n",
      "inventors: 26\n",
      "loss: tensor(0.0221, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.027999999999999997\n",
      "pnl: 0.015\n",
      "inv reward: 0.013\n",
      "inventors: -74\n",
      "loss: tensor(0.3813, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0382\n",
      "pnl: -0.0012\n",
      "inv reward: -0.037\n",
      "inventors: -66\n",
      "loss: tensor(0.3696, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.065\n",
      "pnl: 0.065\n",
      "inv reward: -0.0\n",
      "inventors: -166\n",
      "loss: tensor(0.0746, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4861\n",
      "pnl: 0.0534\n",
      "inv reward: -0.5395\n",
      "inventors: -266\n",
      "loss: tensor(0.0361, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -266\n",
      "loss: tensor(0.2089, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0665\n",
      "pnl: 0\n",
      "inv reward: 0.0665\n",
      "inventors: -266\n",
      "loss: tensor(0.0381, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -266\n",
      "loss: tensor(0.4030, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.20085\n",
      "pnl: -0.00135\n",
      "inv reward: -0.1995\n",
      "inventors: -239\n",
      "loss: tensor(0.1797, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -239\n",
      "loss: tensor(4.3382e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3585\n",
      "pnl: 0\n",
      "inv reward: -0.3585\n",
      "inventors: -239\n",
      "loss: tensor(0.3120, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.29875\n",
      "pnl: 0\n",
      "inv reward: 0.29875\n",
      "inventors: -239\n",
      "loss: tensor(0.5813, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.11725\n",
      "pnl: 0.00225\n",
      "inv reward: -0.1195\n",
      "inventors: -254\n",
      "loss: tensor(0.3645, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.6\n",
      "pnl: 0.035\n",
      "inv reward: -0.635\n",
      "inventors: -354\n",
      "loss: tensor(0.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -354\n",
      "loss: tensor(1.6370, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.35574999999999996\n",
      "pnl: 0.00175\n",
      "inv reward: 0.354\n",
      "inventors: -347\n",
      "loss: tensor(0.8819, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -347\n",
      "loss: tensor(0.0046, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.43375\n",
      "pnl: 0\n",
      "inv reward: 0.43375\n",
      "inventors: -347\n",
      "loss: tensor(1.2048, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.26025\n",
      "pnl: 0\n",
      "inv reward: -0.26025\n",
      "inventors: -347\n",
      "loss: tensor(0.0171, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00175\n",
      "pnl: -0.00175\n",
      "inv reward: -0.0\n",
      "inventors: -312\n",
      "loss: tensor(1.0980, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.156\n",
      "pnl: 0\n",
      "inv reward: -0.156\n",
      "inventors: -312\n",
      "loss: tensor(0.0135, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.156\n",
      "pnl: 0\n",
      "inv reward: -0.156\n",
      "inventors: -312\n",
      "loss: tensor(1.2908, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1674\n",
      "pnl: 0.0114\n",
      "inv reward: 0.156\n",
      "inventors: -236\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00945\n",
      "pnl: 0.00945\n",
      "inv reward: -0.0\n",
      "inventors: -173\n",
      "loss: tensor(0.2673, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08424999999999999\n",
      "pnl: 0.00225\n",
      "inv reward: -0.0865\n",
      "inventors: -158\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.094\n",
      "pnl: 0.015\n",
      "inv reward: 0.079\n",
      "inventors: -58\n",
      "loss: tensor(4.1040, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0435\n",
      "pnl: 0\n",
      "inv reward: 0.0435\n",
      "inventors: -58\n",
      "loss: tensor(0.8300, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -58\n",
      "loss: tensor(0.1021, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0737\n",
      "pnl: -0.0012\n",
      "inv reward: -0.0725\n",
      "inventors: -52\n",
      "loss: tensor(0.1009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -52\n",
      "loss: tensor(0.0822, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.13\n",
      "pnl: 0\n",
      "inv reward: -0.13\n",
      "inventors: -52\n",
      "loss: tensor(1.5441, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.117\n",
      "pnl: 0\n",
      "inv reward: -0.117\n",
      "inventors: -52\n",
      "loss: tensor(2.0157, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.014199999999999999\n",
      "pnl: -0.0012\n",
      "inv reward: -0.013\n",
      "inventors: -46\n",
      "loss: tensor(1.0080, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.04675\n",
      "pnl: -0.00075\n",
      "inv reward: -0.046\n",
      "inventors: -41\n",
      "loss: tensor(0.2060, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00075\n",
      "pnl: -0.00075\n",
      "inv reward: -0.0\n",
      "inventors: -36\n",
      "loss: tensor(0.6692, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.008650000000000001\n",
      "pnl: 0.02665\n",
      "inv reward: -0.018\n",
      "inventors: -77\n",
      "loss: tensor(1.3876, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.21175\n",
      "pnl: 0\n",
      "inv reward: -0.21175\n",
      "inventors: -77\n",
      "loss: tensor(6.9002, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.38125\n",
      "pnl: 0.1\n",
      "inv reward: -0.48125\n",
      "inventors: -177\n",
      "loss: tensor(6.6861, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.531\n",
      "pnl: 0\n",
      "inv reward: -0.531\n",
      "inventors: -177\n",
      "loss: tensor(1.1620, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0822\n",
      "pnl: 0.0063\n",
      "inv reward: -0.0885\n",
      "inventors: -219\n",
      "loss: tensor(0.0848, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27375\n",
      "pnl: 0\n",
      "inv reward: -0.27375\n",
      "inventors: -219\n",
      "loss: tensor(0.1995, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1095\n",
      "pnl: 0\n",
      "inv reward: -0.1095\n",
      "inventors: -219\n",
      "loss: tensor(1.7423, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.05915\n",
      "pnl: -0.0044\n",
      "inv reward: -0.05475\n",
      "inventors: -197\n",
      "loss: tensor(1.1208, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.39449999999999996\n",
      "pnl: 0.04875\n",
      "inv reward: -0.44325\n",
      "inventors: -272\n",
      "loss: tensor(1.0797, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08600000000000001\n",
      "pnl: 0.05\n",
      "inv reward: -0.136\n",
      "inventors: -372\n",
      "loss: tensor(4.5339, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.488\n",
      "pnl: 0\n",
      "inv reward: -1.488\n",
      "inventors: -372\n",
      "loss: tensor(6.0666, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.42500000000000004\n",
      "pnl: 0.04\n",
      "inv reward: -0.465\n",
      "inventors: -472\n",
      "loss: tensor(0.2163, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.236\n",
      "pnl: 0\n",
      "inv reward: -0.236\n",
      "inventors: -472\n",
      "loss: tensor(0.1654, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -9.253\n",
      "pnl: 0.305\n",
      "inv reward: -9.558\n",
      "inventors: -572\n",
      "loss: tensor(0.0625, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.657\n",
      "pnl: 0.083\n",
      "inv reward: 2.574\n",
      "inventors: -489\n",
      "loss: tensor(0.2824, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.75725\n",
      "pnl: 0.0765\n",
      "inv reward: -1.83375\n",
      "inventors: -404\n",
      "loss: tensor(0.0219, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -404\n",
      "loss: tensor(1.7042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.9319999999999999\n",
      "pnl: 0.225\n",
      "inv reward: 0.707\n",
      "inventors: -304\n",
      "loss: tensor(0.0105, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 5.168\n",
      "pnl: 0\n",
      "inv reward: 5.168\n",
      "inventors: -304\n",
      "loss: tensor(24.4057, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.104\n",
      "pnl: 0\n",
      "inv reward: -4.104\n",
      "inventors: -304\n",
      "loss: tensor(12.6871, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.13\n",
      "pnl: 0.13\n",
      "inv reward: -0.0\n",
      "inventors: -404\n",
      "loss: tensor(1.6321, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.092\n",
      "pnl: 0.13\n",
      "inv reward: -2.222\n",
      "inventors: -504\n",
      "loss: tensor(3.0556, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -504\n",
      "loss: tensor(0.0340, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.126\n",
      "pnl: 0\n",
      "inv reward: 0.126\n",
      "inventors: -504\n",
      "loss: tensor(2.4204, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -504\n",
      "loss: tensor(0.1978, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.52255\n",
      "pnl: 0.00255\n",
      "inv reward: 2.52\n",
      "inventors: -453\n",
      "loss: tensor(3.8009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6795\n",
      "pnl: 0\n",
      "inv reward: 0.6795\n",
      "inventors: -453\n",
      "loss: tensor(2.1871, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.21150000000000002\n",
      "pnl: 0.015\n",
      "inv reward: -0.2265\n",
      "inventors: -553\n",
      "loss: tensor(0.1540, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -553\n",
      "loss: tensor(0.1206, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -553\n",
      "loss: tensor(0.0633, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2765\n",
      "pnl: 0\n",
      "inv reward: -0.2765\n",
      "inventors: -553\n",
      "loss: tensor(0.0004, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -553\n",
      "loss: tensor(5.3770, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -553\n",
      "loss: tensor(3.9614, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00285\n",
      "pnl: 0.00285\n",
      "inv reward: -0.0\n",
      "inventors: -572\n",
      "loss: tensor(0.0840, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27385\n",
      "pnl: 0.01215\n",
      "inv reward: -0.286\n",
      "inventors: -653\n",
      "loss: tensor(0.0194, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3265\n",
      "pnl: 0\n",
      "inv reward: 0.3265\n",
      "inventors: -653\n",
      "loss: tensor(0.1136, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -653\n",
      "loss: tensor(2.3259, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3265\n",
      "pnl: 0\n",
      "inv reward: 0.3265\n",
      "inventors: -653\n",
      "loss: tensor(0.3912, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -653\n",
      "loss: tensor(0.9060, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.50775\n",
      "pnl: 0.018\n",
      "inv reward: 0.48975\n",
      "inventors: -581\n",
      "loss: tensor(4.2892, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.41575\n",
      "pnl: 0.02\n",
      "inv reward: -0.43575\n",
      "inventors: -681\n",
      "loss: tensor(3.0979, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3405\n",
      "pnl: 0\n",
      "inv reward: -0.3405\n",
      "inventors: -681\n",
      "loss: tensor(0.0462, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3405\n",
      "pnl: 0\n",
      "inv reward: 0.3405\n",
      "inventors: -681\n",
      "loss: tensor(0.3666, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.33705\n",
      "pnl: 0.00345\n",
      "inv reward: -0.3405\n",
      "inventors: -612\n",
      "loss: tensor(8.9897, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.9432\n",
      "pnl: 0.0252\n",
      "inv reward: 0.918\n",
      "inventors: -556\n",
      "loss: tensor(5.3779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.556\n",
      "pnl: 0\n",
      "inv reward: 0.556\n",
      "inventors: -556\n",
      "loss: tensor(4.3363, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.695\n",
      "pnl: 0\n",
      "inv reward: -0.695\n",
      "inventors: -556\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.7006\n",
      "pnl: 0.0056\n",
      "inv reward: 0.695\n",
      "inventors: -549\n",
      "loss: tensor(1.5356, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.05875\n",
      "pnl: 0\n",
      "inv reward: 2.05875\n",
      "inventors: -549\n",
      "loss: tensor(16.1865, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.44175\n",
      "pnl: 0.03\n",
      "inv reward: 0.41175\n",
      "inventors: -449\n",
      "loss: tensor(1.1006, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2245\n",
      "pnl: 0\n",
      "inv reward: 0.2245\n",
      "inventors: -449\n",
      "loss: tensor(6.6305, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1188\n",
      "pnl: -0.00655\n",
      "inv reward: -0.11225\n",
      "inventors: -404\n",
      "loss: tensor(1.0602, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.9690000000000001\n",
      "pnl: 0.06\n",
      "inv reward: 0.909\n",
      "inventors: -304\n",
      "loss: tensor(0.3050, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.836\n",
      "pnl: 0\n",
      "inv reward: 0.836\n",
      "inventors: -304\n",
      "loss: tensor(0.0264, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6223\n",
      "pnl: 0.0143\n",
      "inv reward: 0.608\n",
      "inventors: -291\n",
      "loss: tensor(0.5865, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.21825\n",
      "pnl: 0\n",
      "inv reward: 0.21825\n",
      "inventors: -291\n",
      "loss: tensor(1.2340, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.582\n",
      "pnl: 0\n",
      "inv reward: 0.582\n",
      "inventors: -291\n",
      "loss: tensor(5.2288, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.50925\n",
      "pnl: 0\n",
      "inv reward: -0.50925\n",
      "inventors: -291\n",
      "loss: tensor(2.3647, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.07275\n",
      "pnl: 0\n",
      "inv reward: -0.07275\n",
      "inventors: -291\n",
      "loss: tensor(0.9883, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.291\n",
      "pnl: 0\n",
      "inv reward: 0.291\n",
      "inventors: -291\n",
      "loss: tensor(0.0177, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -291\n",
      "loss: tensor(0.9340, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.36375\n",
      "pnl: 0\n",
      "inv reward: -0.36375\n",
      "inventors: -291\n",
      "loss: tensor(0.6858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.07275\n",
      "pnl: 0\n",
      "inv reward: 0.07275\n",
      "inventors: -291\n",
      "loss: tensor(0.8402, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4365\n",
      "pnl: 0\n",
      "inv reward: -0.4365\n",
      "inventors: -291\n",
      "loss: tensor(0.2306, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01245\n",
      "pnl: 0.01245\n",
      "inv reward: -0.0\n",
      "inventors: -208\n",
      "loss: tensor(0.1559, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.52105\n",
      "pnl: 0.00105\n",
      "inv reward: 0.52\n",
      "inventors: -187\n",
      "loss: tensor(0.9685, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.374\n",
      "pnl: 0\n",
      "inv reward: 0.374\n",
      "inventors: -187\n",
      "loss: tensor(0.1951, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -187\n",
      "loss: tensor(0.1724, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.374\n",
      "pnl: 0\n",
      "inv reward: 0.374\n",
      "inventors: -187\n",
      "loss: tensor(0.8107, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23375\n",
      "pnl: 0\n",
      "inv reward: 0.23375\n",
      "inventors: -187\n",
      "loss: tensor(0.2133, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0024\n",
      "pnl: 0.0024\n",
      "inv reward: -0.0\n",
      "inventors: -181\n",
      "loss: tensor(0.0258, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.22625\n",
      "pnl: 0\n",
      "inv reward: 0.22625\n",
      "inventors: -181\n",
      "loss: tensor(1.1808, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.80425\n",
      "pnl: 0.035\n",
      "inv reward: 0.76925\n",
      "inventors: -81\n",
      "loss: tensor(1.3027, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -81\n",
      "loss: tensor(0.1506, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.02025\n",
      "pnl: 0\n",
      "inv reward: -0.02025\n",
      "inventors: -81\n",
      "loss: tensor(0.9718, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0405\n",
      "pnl: 0\n",
      "inv reward: -0.0405\n",
      "inventors: -81\n",
      "loss: tensor(0.0351, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.035\n",
      "pnl: 0.035\n",
      "inv reward: -0.0\n",
      "inventors: -181\n",
      "loss: tensor(0.5097, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0905\n",
      "pnl: 0\n",
      "inv reward: -0.0905\n",
      "inventors: -181\n",
      "loss: tensor(0.0025, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1055\n",
      "pnl: 0.015\n",
      "inv reward: 0.0905\n",
      "inventors: -81\n",
      "loss: tensor(0.0301, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -81\n",
      "loss: tensor(0.0050, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -81\n",
      "loss: tensor(0.2567, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0555\n",
      "pnl: 0.015\n",
      "inv reward: 0.0405\n",
      "inventors: 19\n",
      "loss: tensor(0.1208, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.017750000000000002\n",
      "pnl: 0.025\n",
      "inv reward: -0.04275\n",
      "inventors: 119\n",
      "loss: tensor(0.7701, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.16824999999999998\n",
      "pnl: 0.04\n",
      "inv reward: -0.20825\n",
      "inventors: 219\n",
      "loss: tensor(0.7967, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.16425\n",
      "pnl: 0\n",
      "inv reward: -0.16425\n",
      "inventors: 219\n",
      "loss: tensor(0.0186, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27375\n",
      "pnl: 0\n",
      "inv reward: -0.27375\n",
      "inventors: 219\n",
      "loss: tensor(0.6832, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2136\n",
      "pnl: 0.0054\n",
      "inv reward: -0.219\n",
      "inventors: 183\n",
      "loss: tensor(0.4472, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.183\n",
      "pnl: 0\n",
      "inv reward: -0.183\n",
      "inventors: 183\n",
      "loss: tensor(0.1300, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 183\n",
      "loss: tensor(0.7657, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.09245\n",
      "pnl: -0.00095\n",
      "inv reward: -0.0915\n",
      "inventors: 164\n",
      "loss: tensor(0.0075, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 164\n",
      "loss: tensor(0.5808, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.082\n",
      "pnl: 0\n",
      "inv reward: 0.082\n",
      "inventors: 164\n",
      "loss: tensor(0.1262, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 164\n",
      "loss: tensor(0.0475, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 164\n",
      "loss: tensor(0.5506, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 164\n",
      "loss: tensor(0.0467, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.082\n",
      "pnl: 0\n",
      "inv reward: 0.082\n",
      "inventors: 164\n",
      "loss: tensor(0.0650, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.164\n",
      "pnl: 0\n",
      "inv reward: -0.164\n",
      "inventors: 164\n",
      "loss: tensor(0.1707, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.47600000000000003\n",
      "pnl: 0.025\n",
      "inv reward: 0.451\n",
      "inventors: 64\n",
      "loss: tensor(0.7905, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.048\n",
      "pnl: 0\n",
      "inv reward: 0.048\n",
      "inventors: 64\n",
      "loss: tensor(0.2776, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.112\n",
      "pnl: 0\n",
      "inv reward: -0.112\n",
      "inventors: 64\n",
      "loss: tensor(0.4072, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.016\n",
      "pnl: 0\n",
      "inv reward: 0.016\n",
      "inventors: 64\n",
      "loss: tensor(0.8387, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.064\n",
      "pnl: 0\n",
      "inv reward: -0.064\n",
      "inventors: 64\n",
      "loss: tensor(0.1545, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.032\n",
      "pnl: 0\n",
      "inv reward: 0.032\n",
      "inventors: 64\n",
      "loss: tensor(0.2434, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.01975\n",
      "pnl: 0.01225\n",
      "inv reward: -0.032\n",
      "inventors: 113\n",
      "loss: tensor(0.2186, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.055\n",
      "pnl: 0.0015\n",
      "inv reward: -0.0565\n",
      "inventors: 123\n",
      "loss: tensor(0.7705, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0465\n",
      "pnl: 0.015\n",
      "inv reward: -0.0615\n",
      "inventors: 223\n",
      "loss: tensor(0.0260, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.208\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.223\n",
      "inventors: 123\n",
      "loss: tensor(0.9934, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.281\n",
      "pnl: 0.035\n",
      "inv reward: 0.246\n",
      "inventors: 23\n",
      "loss: tensor(0.0136, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.01195\n",
      "pnl: -0.00045\n",
      "inv reward: -0.0115\n",
      "inventors: 20\n",
      "loss: tensor(0.0633, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.04\n",
      "pnl: 0\n",
      "inv reward: -0.04\n",
      "inventors: 20\n",
      "loss: tensor(0.1189, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.035\n",
      "pnl: 0.015\n",
      "inv reward: -0.05\n",
      "inventors: 120\n",
      "loss: tensor(0.3864, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.06\n",
      "pnl: 0\n",
      "inv reward: -0.06\n",
      "inventors: 120\n",
      "loss: tensor(0.1533, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.39\n",
      "pnl: 0\n",
      "inv reward: -0.39\n",
      "inventors: 120\n",
      "loss: tensor(0.4623, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.03\n",
      "pnl: 0\n",
      "inv reward: 0.03\n",
      "inventors: 120\n",
      "loss: tensor(0.3787, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.09\n",
      "pnl: 0\n",
      "inv reward: -0.09\n",
      "inventors: 120\n",
      "loss: tensor(0.5711, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0924\n",
      "pnl: -0.0024\n",
      "inv reward: -0.09\n",
      "inventors: 108\n",
      "loss: tensor(0.1267, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.243\n",
      "pnl: 0\n",
      "inv reward: -0.243\n",
      "inventors: 108\n",
      "loss: tensor(3.4877, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.243\n",
      "pnl: 0\n",
      "inv reward: 0.243\n",
      "inventors: 108\n",
      "loss: tensor(0.8372, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.243\n",
      "pnl: 0\n",
      "inv reward: -0.243\n",
      "inventors: 108\n",
      "loss: tensor(0.0098, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 108\n",
      "loss: tensor(3.0822, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.162\n",
      "pnl: 0\n",
      "inv reward: -0.162\n",
      "inventors: 108\n",
      "loss: tensor(2.7263, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.027\n",
      "pnl: 0\n",
      "inv reward: 0.027\n",
      "inventors: 108\n",
      "loss: tensor(0.3364, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.12000000000000001\n",
      "pnl: 0.015\n",
      "inv reward: -0.135\n",
      "inventors: 208\n",
      "loss: tensor(0.3775, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 208\n",
      "loss: tensor(0.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.156\n",
      "pnl: 0\n",
      "inv reward: -0.156\n",
      "inventors: 208\n",
      "loss: tensor(0.1029, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 208\n",
      "loss: tensor(0.7487, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.728\n",
      "pnl: 0\n",
      "inv reward: -0.728\n",
      "inventors: 208\n",
      "loss: tensor(0.1019, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.5370000000000001\n",
      "pnl: 0.075\n",
      "inv reward: -1.612\n",
      "inventors: 308\n",
      "loss: tensor(0.3568, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.847\n",
      "pnl: 0\n",
      "inv reward: 0.847\n",
      "inventors: 308\n",
      "loss: tensor(0.2490, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.308\n",
      "pnl: 0\n",
      "inv reward: -0.308\n",
      "inventors: 308\n",
      "loss: tensor(0.1017, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4899\n",
      "pnl: 0.0279\n",
      "inv reward: 0.462\n",
      "inventors: 246\n",
      "loss: tensor(0.2827, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.246\n",
      "pnl: 0\n",
      "inv reward: 0.246\n",
      "inventors: 246\n",
      "loss: tensor(1.3612, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0615\n",
      "pnl: 0\n",
      "inv reward: -0.0615\n",
      "inventors: 246\n",
      "loss: tensor(0.0584, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.123\n",
      "pnl: 0\n",
      "inv reward: -0.123\n",
      "inventors: 246\n",
      "loss: tensor(0.5383, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2875\n",
      "pnl: 0.02\n",
      "inv reward: -0.3075\n",
      "inventors: 346\n",
      "loss: tensor(0.7447, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 346\n",
      "loss: tensor(0.9702, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0865\n",
      "pnl: 0\n",
      "inv reward: -0.0865\n",
      "inventors: 346\n",
      "loss: tensor(1.0946, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7616999999999999\n",
      "pnl: 0.0168\n",
      "inv reward: -0.7785\n",
      "inventors: 370\n",
      "loss: tensor(0.0698, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.0175\n",
      "pnl: 0\n",
      "inv reward: -1.0175\n",
      "inventors: 370\n",
      "loss: tensor(0.6842, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2775\n",
      "pnl: 0\n",
      "inv reward: 0.2775\n",
      "inventors: 370\n",
      "loss: tensor(0.3885, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4625\n",
      "pnl: 0\n",
      "inv reward: -0.4625\n",
      "inventors: 370\n",
      "loss: tensor(0.0974, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 370\n",
      "loss: tensor(0.2838, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -8.5137\n",
      "pnl: -0.0962\n",
      "inv reward: -8.4175\n",
      "inventors: 333\n",
      "loss: tensor(2.8595, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.24875\n",
      "pnl: 0\n",
      "inv reward: -1.24875\n",
      "inventors: 333\n",
      "loss: tensor(1.1524, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.333\n",
      "pnl: 0\n",
      "inv reward: 0.333\n",
      "inventors: 333\n",
      "loss: tensor(0.2484, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.8325\n",
      "pnl: 0\n",
      "inv reward: 0.8325\n",
      "inventors: 333\n",
      "loss: tensor(3.4439, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.58275\n",
      "pnl: 0\n",
      "inv reward: 0.58275\n",
      "inventors: 333\n",
      "loss: tensor(2.1499, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 333\n",
      "loss: tensor(1.2925, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.24975\n",
      "pnl: 0\n",
      "inv reward: -0.24975\n",
      "inventors: 333\n",
      "loss: tensor(3.5285, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.25695\n",
      "pnl: 0.0072\n",
      "inv reward: 0.24975\n",
      "inventors: 297\n",
      "loss: tensor(2.6265, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 197\n",
      "loss: tensor(4.6641, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 197\n",
      "loss: tensor(0.8637, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1135\n",
      "pnl: 0.015\n",
      "inv reward: 0.0985\n",
      "inventors: 97\n",
      "loss: tensor(0.6943, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.388\n",
      "pnl: 0\n",
      "inv reward: 0.388\n",
      "inventors: 97\n",
      "loss: tensor(0.1327, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.097\n",
      "pnl: 0\n",
      "inv reward: 0.097\n",
      "inventors: 97\n",
      "loss: tensor(2.6414, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0485\n",
      "pnl: 0\n",
      "inv reward: -0.0485\n",
      "inventors: 97\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1455\n",
      "pnl: 0\n",
      "inv reward: -0.1455\n",
      "inventors: 97\n",
      "loss: tensor(0.0432, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.057749999999999996\n",
      "pnl: 0.015\n",
      "inv reward: -0.07275\n",
      "inventors: 197\n",
      "loss: tensor(1.0951, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.04925\n",
      "pnl: 0\n",
      "inv reward: 0.04925\n",
      "inventors: 197\n",
      "loss: tensor(0.3678, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.24625\n",
      "pnl: 0\n",
      "inv reward: 0.24625\n",
      "inventors: 197\n",
      "loss: tensor(0.0915, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.006\n",
      "pnl: -0.006\n",
      "inv reward: 0.0\n",
      "inventors: 177\n",
      "loss: tensor(0.7742, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.39825\n",
      "pnl: 0\n",
      "inv reward: -0.39825\n",
      "inventors: 177\n",
      "loss: tensor(1.5303, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.354\n",
      "pnl: 0\n",
      "inv reward: -0.354\n",
      "inventors: 177\n",
      "loss: tensor(0.0537, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0885\n",
      "pnl: 0\n",
      "inv reward: 0.0885\n",
      "inventors: 177\n",
      "loss: tensor(0.5043, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.08395\n",
      "pnl: 0.00455\n",
      "inv reward: -0.0885\n",
      "inventors: 164\n",
      "loss: tensor(0.8494, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.082\n",
      "pnl: 0\n",
      "inv reward: 0.082\n",
      "inventors: 164\n",
      "loss: tensor(1.2952, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.082\n",
      "pnl: 0\n",
      "inv reward: -0.082\n",
      "inventors: 164\n",
      "loss: tensor(0.4313, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.082\n",
      "pnl: 0\n",
      "inv reward: 0.082\n",
      "inventors: 164\n",
      "loss: tensor(0.4359, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.246\n",
      "pnl: 0\n",
      "inv reward: 0.246\n",
      "inventors: 164\n",
      "loss: tensor(1.8054, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23195\n",
      "pnl: 0.02695\n",
      "inv reward: 0.205\n",
      "inventors: 87\n",
      "loss: tensor(0.1130, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.06875\n",
      "pnl: 0.04\n",
      "inv reward: -0.10875\n",
      "inventors: 187\n",
      "loss: tensor(0.3076, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.04675\n",
      "pnl: 0\n",
      "inv reward: -0.04675\n",
      "inventors: 187\n",
      "loss: tensor(1.6642, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.34725\n",
      "pnl: 0.02\n",
      "inv reward: 0.32725\n",
      "inventors: 87\n",
      "loss: tensor(1.2762, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.061099999999999995\n",
      "pnl: 0.0259\n",
      "inv reward: -0.087\n",
      "inventors: 187\n",
      "loss: tensor(1.1033, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23375\n",
      "pnl: 0\n",
      "inv reward: 0.23375\n",
      "inventors: 187\n",
      "loss: tensor(0.0080, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 187\n",
      "loss: tensor(4.9927, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23375\n",
      "pnl: 0\n",
      "inv reward: 0.23375\n",
      "inventors: 187\n",
      "loss: tensor(2.6481, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.162\n",
      "pnl: 0.025\n",
      "inv reward: -0.187\n",
      "inventors: 287\n",
      "loss: tensor(0.0177, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1435\n",
      "pnl: 0\n",
      "inv reward: -0.1435\n",
      "inventors: 287\n",
      "loss: tensor(0.0067, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.035\n",
      "pnl: 0.035\n",
      "inv reward: 0.0\n",
      "inventors: 387\n",
      "loss: tensor(2.1864, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9675\n",
      "pnl: 0\n",
      "inv reward: -0.9675\n",
      "inventors: 387\n",
      "loss: tensor(0.1627, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 387\n",
      "loss: tensor(0.2429, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 387\n",
      "loss: tensor(0.7350, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.46875\n",
      "pnl: 0.015\n",
      "inv reward: -0.48375\n",
      "inventors: 487\n",
      "loss: tensor(0.4510, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4885\n",
      "pnl: 0.0015\n",
      "inv reward: 0.487\n",
      "inventors: 482\n",
      "loss: tensor(2.0975, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3615\n",
      "pnl: 0\n",
      "inv reward: -0.3615\n",
      "inventors: 482\n",
      "loss: tensor(0.0022, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.11134999999999999\n",
      "pnl: 0.00915\n",
      "inv reward: -0.1205\n",
      "inventors: 543\n",
      "loss: tensor(0.1575, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.40725\n",
      "pnl: 0\n",
      "inv reward: -0.40725\n",
      "inventors: 543\n",
      "loss: tensor(0.0371, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2715\n",
      "pnl: 0\n",
      "inv reward: 0.2715\n",
      "inventors: 543\n",
      "loss: tensor(0.0391, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2715\n",
      "pnl: 0\n",
      "inv reward: -0.2715\n",
      "inventors: 543\n",
      "loss: tensor(1.2659, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 643\n",
      "loss: tensor(0.7339, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.5825\n",
      "pnl: 0.025\n",
      "inv reward: -1.6075\n",
      "inventors: 743\n",
      "loss: tensor(0.0115, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.319\n",
      "pnl: 0.01875\n",
      "inv reward: 1.30025\n",
      "inventors: 668\n",
      "loss: tensor(0.2496, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.435\n",
      "pnl: 0.07\n",
      "inv reward: -2.505\n",
      "inventors: 768\n",
      "loss: tensor(0.8779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.54755\n",
      "pnl: 0.01155\n",
      "inv reward: 1.536\n",
      "inventors: 691\n",
      "loss: tensor(2.1733, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(0.0483, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(1.2005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(0.1779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.49324999999999997\n",
      "pnl: 0.025\n",
      "inv reward: -0.51825\n",
      "inventors: 791\n",
      "loss: tensor(0.7102, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.59325\n",
      "pnl: 0\n",
      "inv reward: -0.59325\n",
      "inventors: 791\n",
      "loss: tensor(1.3635, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.791\n",
      "pnl: 0\n",
      "inv reward: 0.791\n",
      "inventors: 791\n",
      "loss: tensor(0.8372, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.791\n",
      "pnl: 0\n",
      "inv reward: -0.791\n",
      "inventors: 791\n",
      "loss: tensor(0.5632, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.59325\n",
      "pnl: 0\n",
      "inv reward: 0.59325\n",
      "inventors: 791\n",
      "loss: tensor(0.0091, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.57325\n",
      "pnl: 0.02\n",
      "inv reward: -0.59325\n",
      "inventors: 891\n",
      "loss: tensor(0.1065, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.3715\n",
      "pnl: 0.035\n",
      "inv reward: 1.3365\n",
      "inventors: 791\n",
      "loss: tensor(2.0445, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3955\n",
      "pnl: 0\n",
      "inv reward: 0.3955\n",
      "inventors: 791\n",
      "loss: tensor(0.7641, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.791\n",
      "pnl: 0\n",
      "inv reward: -0.791\n",
      "inventors: 791\n",
      "loss: tensor(0.3423, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 791\n",
      "loss: tensor(0.7037, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3955\n",
      "pnl: 0\n",
      "inv reward: 0.3955\n",
      "inventors: 791\n",
      "loss: tensor(0.5982, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 791\n",
      "loss: tensor(0.2184, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3805\n",
      "pnl: 0.015\n",
      "inv reward: -0.3955\n",
      "inventors: 891\n",
      "loss: tensor(0.0160, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4455\n",
      "pnl: 0\n",
      "inv reward: -0.4455\n",
      "inventors: 891\n",
      "loss: tensor(1.1084, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4371\n",
      "pnl: 0.0084\n",
      "inv reward: -0.4455\n",
      "inventors: 835\n",
      "loss: tensor(0.0122, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4175\n",
      "pnl: 0\n",
      "inv reward: 0.4175\n",
      "inventors: 835\n",
      "loss: tensor(2.1803, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.62625\n",
      "pnl: 0\n",
      "inv reward: 0.62625\n",
      "inventors: 835\n",
      "loss: tensor(0.0021, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.20875\n",
      "pnl: 0\n",
      "inv reward: -0.20875\n",
      "inventors: 835\n",
      "loss: tensor(2.3579, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4175\n",
      "pnl: 0\n",
      "inv reward: 0.4175\n",
      "inventors: 835\n",
      "loss: tensor(0.8858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 835\n",
      "loss: tensor(0.7353, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.62625\n",
      "pnl: 0\n",
      "inv reward: 0.62625\n",
      "inventors: 835\n",
      "loss: tensor(1.1505, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0042\n",
      "pnl: 0.0042\n",
      "inv reward: 0.0\n",
      "inventors: 814\n",
      "loss: tensor(2.3369, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.0375\n",
      "pnl: 0.02\n",
      "inv reward: 1.0175\n",
      "inventors: 714\n",
      "loss: tensor(0.8847, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.357\n",
      "pnl: 0\n",
      "inv reward: -0.357\n",
      "inventors: 714\n",
      "loss: tensor(2.7383, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.046\n",
      "pnl: 0.025\n",
      "inv reward: -1.071\n",
      "inventors: 814\n",
      "loss: tensor(2.6084, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 814\n",
      "loss: tensor(0.3167, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.42589999999999995\n",
      "pnl: -0.0189\n",
      "inv reward: -0.407\n",
      "inventors: 732\n",
      "loss: tensor(1.6256, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.035\n",
      "pnl: 0.035\n",
      "inv reward: 0.0\n",
      "inventors: 832\n",
      "loss: tensor(0.0029, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.7070000000000003\n",
      "pnl: 0.037\n",
      "inv reward: -3.744\n",
      "inventors: 932\n",
      "loss: tensor(0.1296, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.233\n",
      "pnl: 0\n",
      "inv reward: -0.233\n",
      "inventors: 932\n",
      "loss: tensor(2.3553, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.3778\n",
      "pnl: 0.0478\n",
      "inv reward: 2.33\n",
      "inventors: 871\n",
      "loss: tensor(3.7752, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.449\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: -3.484\n",
      "inventors: 971\n",
      "loss: tensor(2.1575, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.72825\n",
      "pnl: 0\n",
      "inv reward: -0.72825\n",
      "inventors: 971\n",
      "loss: tensor(0.0254, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.58725\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: -4.61225\n",
      "inventors: 1071\n",
      "loss: tensor(4.0048, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 3.213\n",
      "pnl: 0\n",
      "inv reward: 3.213\n",
      "inventors: 1071\n",
      "loss: tensor(3.4398, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27854999999999996\n",
      "pnl: -0.0108\n",
      "inv reward: -0.26775\n",
      "inventors: 963\n",
      "loss: tensor(0.0930, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 963\n",
      "loss: tensor(0.4008, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.20375\n",
      "pnl: 0\n",
      "inv reward: 1.20375\n",
      "inventors: 963\n",
      "loss: tensor(1.4979, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.73225\n",
      "pnl: 0.01\n",
      "inv reward: 0.72225\n",
      "inventors: 863\n",
      "loss: tensor(1.5417, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.863\n",
      "pnl: 0\n",
      "inv reward: -0.863\n",
      "inventors: 863\n",
      "loss: tensor(1.3262, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00585\n",
      "pnl: 0.00585\n",
      "inv reward: 0.0\n",
      "inventors: 824\n",
      "loss: tensor(1.5910, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.206\n",
      "pnl: 0\n",
      "inv reward: -0.206\n",
      "inventors: 824\n",
      "loss: tensor(0.5298, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 824\n",
      "loss: tensor(0.6702, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 824\n",
      "loss: tensor(2.2323, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 824\n",
      "loss: tensor(0.0007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.03\n",
      "pnl: 0\n",
      "inv reward: -1.03\n",
      "inventors: 824\n",
      "loss: tensor(2.4476, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 824\n",
      "loss: tensor(0.1086, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.412\n",
      "pnl: 0\n",
      "inv reward: 0.412\n",
      "inventors: 824\n",
      "loss: tensor(0.4531, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.824\n",
      "pnl: 0\n",
      "inv reward: 0.824\n",
      "inventors: 824\n",
      "loss: tensor(0.9508, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.417\n",
      "pnl: 0.005\n",
      "inv reward: 0.412\n",
      "inventors: 724\n",
      "loss: tensor(0.3893, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 724\n",
      "loss: tensor(0.0871, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 724\n",
      "loss: tensor(0.0110, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 724\n",
      "loss: tensor(0.3127, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 724\n",
      "loss: tensor(1.8530, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 624\n",
      "loss: tensor(1.4277, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.312\n",
      "pnl: 0\n",
      "inv reward: 0.312\n",
      "inventors: 624\n",
      "loss: tensor(0.9159, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 624\n",
      "loss: tensor(0.0769, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.624\n",
      "pnl: 0\n",
      "inv reward: 0.624\n",
      "inventors: 624\n",
      "loss: tensor(1.2386, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6255\n",
      "pnl: 0.0015\n",
      "inv reward: 0.624\n",
      "inventors: 618\n",
      "loss: tensor(2.0634, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0031000000000000003\n",
      "pnl: -0.0031000000000000003\n",
      "inv reward: 0.0\n",
      "inventors: 556\n",
      "loss: tensor(0.0371, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 556\n",
      "loss: tensor(0.0281, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.263\n",
      "pnl: 0.015\n",
      "inv reward: -0.278\n",
      "inventors: 656\n",
      "loss: tensor(7.0103e-05, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.82\n",
      "pnl: 0\n",
      "inv reward: -0.82\n",
      "inventors: 656\n",
      "loss: tensor(0.6631, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.82\n",
      "pnl: 0\n",
      "inv reward: 0.82\n",
      "inventors: 656\n",
      "loss: tensor(1.5681, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.29300000000000004\n",
      "pnl: 0.035\n",
      "inv reward: -0.328\n",
      "inventors: 756\n",
      "loss: tensor(0.2156, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.756\n",
      "pnl: 0\n",
      "inv reward: -0.756\n",
      "inventors: 756\n",
      "loss: tensor(0.0006, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.393\n",
      "pnl: 0.015\n",
      "inv reward: 0.378\n",
      "inventors: 656\n",
      "loss: tensor(0.0517, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.313\n",
      "pnl: 0.015\n",
      "inv reward: -0.328\n",
      "inventors: 756\n",
      "loss: tensor(0.3632, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 756\n",
      "loss: tensor(0.1886, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 756\n",
      "loss: tensor(0.4796, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 756\n",
      "loss: tensor(1.2174, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 756\n",
      "loss: tensor(0.4062, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.741\n",
      "pnl: 0.015\n",
      "inv reward: -0.756\n",
      "inventors: 856\n",
      "loss: tensor(0.0939, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 856\n",
      "loss: tensor(1.1765, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00075\n",
      "pnl: 0.00075\n",
      "inv reward: 0.0\n",
      "inventors: 859\n",
      "loss: tensor(0.0220, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.64425\n",
      "pnl: 0\n",
      "inv reward: -0.64425\n",
      "inventors: 859\n",
      "loss: tensor(0.2388, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.21475\n",
      "pnl: 0\n",
      "inv reward: -0.21475\n",
      "inventors: 859\n",
      "loss: tensor(0.9627, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 859\n",
      "loss: tensor(0.2587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4295\n",
      "pnl: 0\n",
      "inv reward: 0.4295\n",
      "inventors: 859\n",
      "loss: tensor(0.0200, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 859\n",
      "loss: tensor(0.4080, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 859\n",
      "loss: tensor(0.1775, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4295\n",
      "pnl: 0\n",
      "inv reward: -0.4295\n",
      "inventors: 859\n",
      "loss: tensor(0.0656, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 859\n",
      "loss: tensor(0.1237, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4375\n",
      "pnl: 0.008\n",
      "inv reward: 0.4295\n",
      "inventors: 827\n",
      "loss: tensor(1.3781, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.8281499999999999\n",
      "pnl: -0.00115\n",
      "inv reward: -0.827\n",
      "inventors: 744\n",
      "loss: tensor(0.0052, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01825\n",
      "pnl: 0.01825\n",
      "inv reward: 0.0\n",
      "inventors: 671\n",
      "loss: tensor(0.2463, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6960000000000001\n",
      "pnl: 0.025\n",
      "inv reward: 0.671\n",
      "inventors: 571\n",
      "loss: tensor(0.4091, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.60425\n",
      "pnl: 0.034\n",
      "inv reward: 1.57025\n",
      "inventors: 471\n",
      "loss: tensor(1.6507, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.30965\n",
      "pnl: -0.0144\n",
      "inv reward: -1.29525\n",
      "inventors: 423\n",
      "loss: tensor(0.1364, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 423\n",
      "loss: tensor(0.7174, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00215\n",
      "pnl: -0.00215\n",
      "inv reward: 0.0\n",
      "inventors: 380\n",
      "loss: tensor(1.0342, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01125\n",
      "pnl: 0.01125\n",
      "inv reward: 0.0\n",
      "inventors: 355\n",
      "loss: tensor(1.0912, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 355\n",
      "loss: tensor(0.1576, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.355\n",
      "pnl: 0\n",
      "inv reward: 0.355\n",
      "inventors: 355\n",
      "loss: tensor(1.7520, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.18289999999999998\n",
      "pnl: -0.0054\n",
      "inv reward: -0.1775\n",
      "inventors: 319\n",
      "loss: tensor(0.4758, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23925\n",
      "pnl: 0\n",
      "inv reward: 0.23925\n",
      "inventors: 319\n",
      "loss: tensor(1.8972, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4785\n",
      "pnl: 0\n",
      "inv reward: 0.4785\n",
      "inventors: 319\n",
      "loss: tensor(0.0032, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.23925\n",
      "pnl: 0\n",
      "inv reward: -0.23925\n",
      "inventors: 319\n",
      "loss: tensor(0.8280, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 319\n",
      "loss: tensor(0.0152, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1745\n",
      "pnl: 0.015\n",
      "inv reward: 0.1595\n",
      "inventors: 219\n",
      "loss: tensor(0.5529, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1095\n",
      "pnl: 0\n",
      "inv reward: 0.1095\n",
      "inventors: 219\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0011\n",
      "pnl: -0.0011\n",
      "inv reward: 0.0\n",
      "inventors: 197\n",
      "loss: tensor(0.0184, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.34049999999999997\n",
      "pnl: 0.045\n",
      "inv reward: 0.2955\n",
      "inventors: 97\n",
      "loss: tensor(0.0540, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.097\n",
      "pnl: 0\n",
      "inv reward: -0.097\n",
      "inventors: 97\n",
      "loss: tensor(0.8109, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.194\n",
      "pnl: 0\n",
      "inv reward: 0.194\n",
      "inventors: 97\n",
      "loss: tensor(0.0362, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 97\n",
      "loss: tensor(1.1198, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0485\n",
      "pnl: 0\n",
      "inv reward: -0.0485\n",
      "inventors: 97\n",
      "loss: tensor(0.9991, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0485\n",
      "pnl: 0\n",
      "inv reward: -0.0485\n",
      "inventors: 97\n",
      "loss: tensor(0.0064, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0485\n",
      "pnl: 0\n",
      "inv reward: -0.0485\n",
      "inventors: 97\n",
      "loss: tensor(0.0102, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 97\n",
      "loss: tensor(0.6567, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.219\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: 0.194\n",
      "inventors: -3\n",
      "loss: tensor(0.9116, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00305\n",
      "pnl: 5e-05\n",
      "inv reward: 0.003\n",
      "inventors: -2\n",
      "loss: tensor(0.0005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0022500000000000003\n",
      "pnl: -0.00025\n",
      "inv reward: -0.002\n",
      "inventors: -1\n",
      "loss: tensor(0.2847, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0005\n",
      "pnl: 0\n",
      "inv reward: 0.0005\n",
      "inventors: -1\n",
      "loss: tensor(0.1324, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.001\n",
      "pnl: 0\n",
      "inv reward: -0.001\n",
      "inventors: -1\n",
      "loss: tensor(0.0226, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.012249999999999999\n",
      "pnl: 0.01275\n",
      "inv reward: -0.0005\n",
      "inventors: -86\n",
      "loss: tensor(1.5017, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.08735\n",
      "pnl: 0.00135\n",
      "inv reward: 0.086\n",
      "inventors: -77\n",
      "loss: tensor(0.2292, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.154\n",
      "pnl: 0\n",
      "inv reward: -0.154\n",
      "inventors: -77\n",
      "loss: tensor(0.3314, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0235\n",
      "pnl: 0.015\n",
      "inv reward: -0.0385\n",
      "inventors: -177\n",
      "loss: tensor(0.5727, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0876\n",
      "pnl: -0.0009\n",
      "inv reward: 0.0885\n",
      "inventors: -159\n",
      "loss: tensor(0.8128, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0795\n",
      "pnl: 0\n",
      "inv reward: -0.0795\n",
      "inventors: -159\n",
      "loss: tensor(1.4176, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0795\n",
      "pnl: 0\n",
      "inv reward: -0.0795\n",
      "inventors: -159\n",
      "loss: tensor(0.0019, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.42250000000000004\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: 0.3975\n",
      "inventors: -59\n",
      "loss: tensor(0.5232, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0295\n",
      "pnl: 0\n",
      "inv reward: 0.0295\n",
      "inventors: -59\n",
      "loss: tensor(1.6135, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0304\n",
      "pnl: -0.0009\n",
      "inv reward: -0.0295\n",
      "inventors: -53\n",
      "loss: tensor(0.8548, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.068\n",
      "pnl: 0.015\n",
      "inv reward: 0.053\n",
      "inventors: 47\n",
      "loss: tensor(0.2708, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0235\n",
      "pnl: 0\n",
      "inv reward: -0.0235\n",
      "inventors: 47\n",
      "loss: tensor(0.9005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.032\n",
      "pnl: 0.015\n",
      "inv reward: -0.047\n",
      "inventors: 147\n",
      "loss: tensor(0.5828, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 147\n",
      "loss: tensor(0.0153, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.16199999999999998\n",
      "pnl: 0.015\n",
      "inv reward: 0.147\n",
      "inventors: 47\n",
      "loss: tensor(1.2397, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 47\n",
      "loss: tensor(1.0736, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 47\n",
      "loss: tensor(0.5139, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0308\n",
      "pnl: 0.0308\n",
      "inv reward: 0.0\n",
      "inventors: -41\n",
      "loss: tensor(2.3382, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.005749999999999998\n",
      "pnl: 0.025\n",
      "inv reward: -0.03075\n",
      "inventors: -141\n",
      "loss: tensor(0.1525, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0015\n",
      "pnl: -0.0015\n",
      "inv reward: -0.0\n",
      "inventors: -126\n",
      "loss: tensor(0.0947, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.04\n",
      "pnl: 0.04\n",
      "inv reward: -0.0\n",
      "inventors: -226\n",
      "loss: tensor(0.4834, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5715\n",
      "pnl: 0.05\n",
      "inv reward: -0.6215\n",
      "inventors: -326\n",
      "loss: tensor(0.1460, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5867\n",
      "pnl: 0.016200000000000003\n",
      "inv reward: 0.5705\n",
      "inventors: -226\n",
      "loss: tensor(1.6157, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.113\n",
      "pnl: 0\n",
      "inv reward: 0.113\n",
      "inventors: -226\n",
      "loss: tensor(0.7775, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2825\n",
      "pnl: 0\n",
      "inv reward: -0.2825\n",
      "inventors: -226\n",
      "loss: tensor(0.5614, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0415\n",
      "pnl: 0.015\n",
      "inv reward: -0.0565\n",
      "inventors: -326\n",
      "loss: tensor(0.0655, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2245\n",
      "pnl: 0.02\n",
      "inv reward: -0.2445\n",
      "inventors: -426\n",
      "loss: tensor(0.0809, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -426\n",
      "loss: tensor(0.3814, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -426\n",
      "loss: tensor(0.0809, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -426\n",
      "loss: tensor(1.1845, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.639\n",
      "pnl: 0\n",
      "inv reward: 0.639\n",
      "inventors: -426\n",
      "loss: tensor(0.0569, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.426\n",
      "pnl: 0\n",
      "inv reward: -0.426\n",
      "inventors: -426\n",
      "loss: tensor(0.5156, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -426\n",
      "loss: tensor(0.9736, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.213\n",
      "pnl: 0\n",
      "inv reward: -0.213\n",
      "inventors: -426\n",
      "loss: tensor(0.0448, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.837\n",
      "pnl: 0.015\n",
      "inv reward: -0.852\n",
      "inventors: -526\n",
      "loss: tensor(1.0480, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3945\n",
      "pnl: 0\n",
      "inv reward: 0.3945\n",
      "inventors: -526\n",
      "loss: tensor(0.5296, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3945\n",
      "pnl: 0\n",
      "inv reward: -0.3945\n",
      "inventors: -526\n",
      "loss: tensor(0.8437, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3945\n",
      "pnl: 0\n",
      "inv reward: -0.3945\n",
      "inventors: -526\n",
      "loss: tensor(0.5857, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1315\n",
      "pnl: 0\n",
      "inv reward: 0.1315\n",
      "inventors: -526\n",
      "loss: tensor(0.3462, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -526\n",
      "loss: tensor(0.7198, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -526\n",
      "loss: tensor(0.1791, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.511\n",
      "pnl: 0.015\n",
      "inv reward: -0.526\n",
      "inventors: -626\n",
      "loss: tensor(1.5235, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4845\n",
      "pnl: 0.015\n",
      "inv reward: 0.4695\n",
      "inventors: -526\n",
      "loss: tensor(1.1068, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3045\n",
      "pnl: 0.09\n",
      "inv reward: -0.3945\n",
      "inventors: -626\n",
      "loss: tensor(0.0742, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -626\n",
      "loss: tensor(0.0326, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.51755\n",
      "pnl: 0.04745\n",
      "inv reward: -1.565\n",
      "inventors: -699\n",
      "loss: tensor(0.3920, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7194999999999999\n",
      "pnl: -0.0205\n",
      "inv reward: -0.699\n",
      "inventors: -629\n",
      "loss: tensor(0.0892, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.6839499999999998\n",
      "pnl: 0.04580000000000001\n",
      "inv reward: -1.72975\n",
      "inventors: -729\n",
      "loss: tensor(8.1315e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.408\n",
      "pnl: 0.05\n",
      "inv reward: -1.458\n",
      "inventors: -829\n",
      "loss: tensor(0.0014, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -8.80175\n",
      "pnl: 0.11000000000000001\n",
      "inv reward: -8.91175\n",
      "inventors: -929\n",
      "loss: tensor(5.2860, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.858\n",
      "pnl: 0\n",
      "inv reward: -1.858\n",
      "inventors: -929\n",
      "loss: tensor(0.1425, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.16125\n",
      "pnl: 0\n",
      "inv reward: 1.16125\n",
      "inventors: -929\n",
      "loss: tensor(1.5953, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -929\n",
      "loss: tensor(0.0898, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.69675\n",
      "pnl: 0\n",
      "inv reward: 0.69675\n",
      "inventors: -929\n",
      "loss: tensor(0.3270, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.1956\n",
      "pnl: -0.03435\n",
      "inv reward: -1.16125\n",
      "inventors: -836\n",
      "loss: tensor(0.0380, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.015\n",
      "pnl: 0.030000000000000002\n",
      "inv reward: -1.045\n",
      "inventors: -936\n",
      "loss: tensor(1.1379, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -936\n",
      "loss: tensor(0.6743, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.20670000000000002\n",
      "pnl: 0.0273\n",
      "inv reward: -0.234\n",
      "inventors: -836\n",
      "loss: tensor(0.0697, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2006\n",
      "pnl: -0.0084\n",
      "inv reward: 0.209\n",
      "inventors: -752\n",
      "loss: tensor(0.0331, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.006699999999999999\n",
      "pnl: -0.006699999999999999\n",
      "inv reward: -0.0\n",
      "inventors: -676\n",
      "loss: tensor(0.0005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.651\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: -0.676\n",
      "inventors: -776\n",
      "loss: tensor(0.0092, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.751\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: -0.776\n",
      "inventors: -876\n",
      "loss: tensor(0.4384, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.920599999999999\n",
      "pnl: -0.1026\n",
      "inv reward: -4.818\n",
      "inventors: -788\n",
      "loss: tensor(4.4863, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.17200000000000001\n",
      "pnl: 0.025\n",
      "inv reward: -0.197\n",
      "inventors: -888\n",
      "loss: tensor(0.7606, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.2638\n",
      "pnl: 0.0682\n",
      "inv reward: -1.332\n",
      "inventors: -988\n",
      "loss: tensor(0.5170, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.235\n",
      "pnl: 0\n",
      "inv reward: -1.235\n",
      "inventors: -988\n",
      "loss: tensor(0.2078, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -988\n",
      "loss: tensor(0.0325, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.0494499999999998\n",
      "pnl: -0.08545\n",
      "inv reward: -2.964\n",
      "inventors: -889\n",
      "loss: tensor(1.6529, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.1775\n",
      "pnl: 0.045\n",
      "inv reward: -2.2225\n",
      "inventors: -989\n",
      "loss: tensor(0.4337, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4945\n",
      "pnl: 0\n",
      "inv reward: -0.4945\n",
      "inventors: -989\n",
      "loss: tensor(0.0105, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(0.1216, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.36125\n",
      "pnl: 0\n",
      "inv reward: -1.36125\n",
      "inventors: -1089\n",
      "loss: tensor(0.1783, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.36125\n",
      "pnl: 0\n",
      "inv reward: 1.36125\n",
      "inventors: -1089\n",
      "loss: tensor(1.6083, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(1.4233, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5445\n",
      "pnl: 0\n",
      "inv reward: 0.5445\n",
      "inventors: -1089\n",
      "loss: tensor(1.1523, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27225\n",
      "pnl: 0\n",
      "inv reward: -0.27225\n",
      "inventors: -1089\n",
      "loss: tensor(1.4353, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.81675\n",
      "pnl: 0\n",
      "inv reward: -0.81675\n",
      "inventors: -1089\n",
      "loss: tensor(0.5356, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(0.4118, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5445\n",
      "pnl: 0\n",
      "inv reward: -0.5445\n",
      "inventors: -1089\n",
      "loss: tensor(0.0021, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(1.2094, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5445\n",
      "pnl: 0\n",
      "inv reward: 0.5445\n",
      "inventors: -1089\n",
      "loss: tensor(0.0244, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(0.9907, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.089\n",
      "pnl: 0\n",
      "inv reward: 1.089\n",
      "inventors: -1089\n",
      "loss: tensor(1.6609, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -1089\n",
      "loss: tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 4.622800000000001\n",
      "pnl: -0.00545\n",
      "inv reward: 4.62825\n",
      "inventors: -980\n",
      "loss: tensor(5.6380, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.225\n",
      "pnl: 0\n",
      "inv reward: -1.225\n",
      "inventors: -980\n",
      "loss: tensor(1.5609, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.075\n",
      "pnl: 0.075\n",
      "inv reward: -0.0\n",
      "inventors: -1080\n",
      "loss: tensor(1.6424, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.51\n",
      "pnl: 0\n",
      "inv reward: -3.51\n",
      "inventors: -1080\n",
      "loss: tensor(4.0153, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2684\n",
      "pnl: -0.0016\n",
      "inv reward: 0.27\n",
      "inventors: -972\n",
      "loss: tensor(0.4282, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.4351\n",
      "pnl: -0.022900000000000004\n",
      "inv reward: 1.458\n",
      "inventors: -874\n",
      "loss: tensor(1.7976, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -874\n",
      "loss: tensor(1.8207, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6555\n",
      "pnl: 0\n",
      "inv reward: 0.6555\n",
      "inventors: -874\n",
      "loss: tensor(1.9631, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.1077000000000001\n",
      "pnl: -0.0152\n",
      "inv reward: -1.0925\n",
      "inventors: -786\n",
      "loss: tensor(0.0329, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -786\n",
      "loss: tensor(0.0143, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -786\n",
      "loss: tensor(0.0817, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.393\n",
      "pnl: 0\n",
      "inv reward: -0.393\n",
      "inventors: -786\n",
      "loss: tensor(0.0026, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015000000000000001\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.0\n",
      "inventors: -886\n",
      "loss: tensor(0.8875, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -886\n",
      "loss: tensor(0.1858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -886\n",
      "loss: tensor(0.2317, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -886\n",
      "loss: tensor(1.8386, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.443\n",
      "pnl: 0\n",
      "inv reward: -0.443\n",
      "inventors: -886\n",
      "loss: tensor(0.7486, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.443\n",
      "pnl: 0\n",
      "inv reward: 0.443\n",
      "inventors: -886\n",
      "loss: tensor(0.2614, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.443\n",
      "pnl: 0\n",
      "inv reward: -0.443\n",
      "inventors: -886\n",
      "loss: tensor(0.0085, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -886\n",
      "loss: tensor(0.2687, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.871\n",
      "pnl: 0.015\n",
      "inv reward: -0.886\n",
      "inventors: -986\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.508\n",
      "pnl: 0.015\n",
      "inv reward: 0.493\n",
      "inventors: -886\n",
      "loss: tensor(0.8051, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4612\n",
      "pnl: 0.0182\n",
      "inv reward: 0.443\n",
      "inventors: -834\n",
      "loss: tensor(1.1393, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.849\n",
      "pnl: 0.015\n",
      "inv reward: 0.834\n",
      "inventors: -734\n",
      "loss: tensor(0.6757, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -734\n",
      "loss: tensor(0.7642, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -734\n",
      "loss: tensor(0.2512, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -734\n",
      "loss: tensor(0.2443, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.1195\n",
      "pnl: 0.0185\n",
      "inv reward: 1.101\n",
      "inventors: -660\n",
      "loss: tensor(2.0768, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -660\n",
      "loss: tensor(0.0101, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -660\n",
      "loss: tensor(0.7059, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.324\n",
      "pnl: 0.006\n",
      "inv reward: -0.33\n",
      "inventors: -684\n",
      "loss: tensor(0.0081, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.342\n",
      "pnl: 0\n",
      "inv reward: 0.342\n",
      "inventors: -684\n",
      "loss: tensor(0.0091, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.3430000000000002\n",
      "pnl: 0.025\n",
      "inv reward: -1.368\n",
      "inventors: -784\n",
      "loss: tensor(0.4424, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: -0.0\n",
      "inventors: -684\n",
      "loss: tensor(0.1609, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6990000000000001\n",
      "pnl: 0.015\n",
      "inv reward: 0.684\n",
      "inventors: -584\n",
      "loss: tensor(0.9296, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.876\n",
      "pnl: 0\n",
      "inv reward: 0.876\n",
      "inventors: -584\n",
      "loss: tensor(1.0731, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.413\n",
      "pnl: 0.025\n",
      "inv reward: -0.438\n",
      "inventors: -684\n",
      "loss: tensor(0.8497, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.197\n",
      "pnl: 0\n",
      "inv reward: 1.197\n",
      "inventors: -684\n",
      "loss: tensor(0.3711, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -684\n",
      "loss: tensor(1.2067, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -684\n",
      "loss: tensor(0.5825, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.665\n",
      "pnl: 0.045\n",
      "inv reward: -1.71\n",
      "inventors: -784\n",
      "loss: tensor(1.2607, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.141\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: -1.176\n",
      "inventors: -884\n",
      "loss: tensor(0.0051, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.442\n",
      "pnl: 0\n",
      "inv reward: -0.442\n",
      "inventors: -884\n",
      "loss: tensor(0.4055, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4294\n",
      "pnl: 0.0126\n",
      "inv reward: -0.442\n",
      "inventors: -968\n",
      "loss: tensor(0.1319, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.242\n",
      "pnl: 0\n",
      "inv reward: 0.242\n",
      "inventors: -968\n",
      "loss: tensor(1.3265, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.242\n",
      "pnl: 0\n",
      "inv reward: -0.242\n",
      "inventors: -968\n",
      "loss: tensor(0.0717, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.242\n",
      "pnl: 0\n",
      "inv reward: 0.242\n",
      "inventors: -968\n",
      "loss: tensor(0.9897, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -968\n",
      "loss: tensor(0.3042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7454\n",
      "pnl: -0.019399999999999997\n",
      "inv reward: -0.726\n",
      "inventors: -871\n",
      "loss: tensor(0.5834, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -871\n",
      "loss: tensor(0.0489, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.95975\n",
      "pnl: 0\n",
      "inv reward: -1.95975\n",
      "inventors: -871\n",
      "loss: tensor(0.4104, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.65325\n",
      "pnl: 0\n",
      "inv reward: -0.65325\n",
      "inventors: -871\n",
      "loss: tensor(0.1495, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.025\n",
      "pnl: 0.025\n",
      "inv reward: -0.0\n",
      "inventors: -771\n",
      "loss: tensor(0.1521, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.3839000000000001\n",
      "pnl: 0.03465\n",
      "inv reward: 1.34925\n",
      "inventors: -694\n",
      "loss: tensor(1.7271, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.22349999999999998\n",
      "pnl: 0.05\n",
      "inv reward: 0.1735\n",
      "inventors: -594\n",
      "loss: tensor(2.5981, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.485\n",
      "pnl: 0\n",
      "inv reward: 1.485\n",
      "inventors: -594\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -594\n",
      "loss: tensor(1.4901, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4455\n",
      "pnl: 0\n",
      "inv reward: 0.4455\n",
      "inventors: -594\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -594\n",
      "loss: tensor(0.7061, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4455\n",
      "pnl: 0\n",
      "inv reward: 0.4455\n",
      "inventors: -594\n",
      "loss: tensor(1.4249, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.297\n",
      "pnl: 0\n",
      "inv reward: 0.297\n",
      "inventors: -594\n",
      "loss: tensor(1.4564, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1485\n",
      "pnl: 0\n",
      "inv reward: 0.1485\n",
      "inventors: -594\n",
      "loss: tensor(0.7561, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1485\n",
      "pnl: 0\n",
      "inv reward: -0.1485\n",
      "inventors: -594\n",
      "loss: tensor(0.0768, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.297\n",
      "pnl: 0\n",
      "inv reward: 0.297\n",
      "inventors: -594\n",
      "loss: tensor(0.2671, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.297\n",
      "pnl: 0\n",
      "inv reward: -0.297\n",
      "inventors: -594\n",
      "loss: tensor(0.2429, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: -0.0\n",
      "inventors: -694\n",
      "loss: tensor(1.2347, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.347\n",
      "pnl: 0\n",
      "inv reward: -0.347\n",
      "inventors: -694\n",
      "loss: tensor(0.0120, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6972999999999999\n",
      "pnl: 0.0033\n",
      "inv reward: 0.694\n",
      "inventors: -672\n",
      "loss: tensor(1.4466, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.3190000000000002\n",
      "pnl: 0.025\n",
      "inv reward: -1.344\n",
      "inventors: -772\n",
      "loss: tensor(0.0991, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.386\n",
      "pnl: 0\n",
      "inv reward: -0.386\n",
      "inventors: -772\n",
      "loss: tensor(0.4807, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.16465\n",
      "pnl: 0.00665\n",
      "inv reward: 1.158\n",
      "inventors: -753\n",
      "loss: tensor(0.1340, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00405\n",
      "pnl: 0.00405\n",
      "inv reward: -0.0\n",
      "inventors: -672\n",
      "loss: tensor(0.3848, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.504\n",
      "pnl: 0\n",
      "inv reward: 0.504\n",
      "inventors: -672\n",
      "loss: tensor(0.6012, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.504\n",
      "pnl: 0\n",
      "inv reward: -0.504\n",
      "inventors: -672\n",
      "loss: tensor(0.1146, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0034000000000000002\n",
      "pnl: -0.0034000000000000002\n",
      "inv reward: -0.0\n",
      "inventors: -604\n",
      "loss: tensor(0.3464, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -604\n",
      "loss: tensor(0.0022, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.604\n",
      "pnl: 0\n",
      "inv reward: 0.604\n",
      "inventors: -604\n",
      "loss: tensor(2.1593, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -604\n",
      "loss: tensor(1.7670, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.9196500000000001\n",
      "pnl: 0.01365\n",
      "inv reward: 0.906\n",
      "inventors: -565\n",
      "loss: tensor(1.3242, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.14125\n",
      "pnl: 0\n",
      "inv reward: 0.14125\n",
      "inventors: -565\n",
      "loss: tensor(0.1174, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.00125\n",
      "pnl: -0.0125\n",
      "inv reward: -0.98875\n",
      "inventors: -508\n",
      "loss: tensor(0.1475, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.254\n",
      "pnl: 0\n",
      "inv reward: -0.254\n",
      "inventors: -508\n",
      "loss: tensor(0.9589, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -508\n",
      "loss: tensor(1.0154, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -508\n",
      "loss: tensor(0.0010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2597\n",
      "pnl: 0.0057\n",
      "inv reward: 0.254\n",
      "inventors: -470\n",
      "loss: tensor(1.4856, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0031\n",
      "pnl: 0.0031\n",
      "inv reward: -0.0\n",
      "inventors: -408\n",
      "loss: tensor(0.0211, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -408\n",
      "loss: tensor(1.0497, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00205\n",
      "pnl: -0.00205\n",
      "inv reward: -0.0\n",
      "inventors: -367\n",
      "loss: tensor(0.3671, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -367\n",
      "loss: tensor(0.0361, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.367\n",
      "pnl: 0\n",
      "inv reward: 0.367\n",
      "inventors: -367\n",
      "loss: tensor(1.8991, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.49375\n",
      "pnl: 0.035\n",
      "inv reward: 0.45875\n",
      "inventors: -267\n",
      "loss: tensor(0.6956, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.46725\n",
      "pnl: 0\n",
      "inv reward: 0.46725\n",
      "inventors: -267\n",
      "loss: tensor(1.5845, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.267\n",
      "pnl: 0\n",
      "inv reward: 0.267\n",
      "inventors: -267\n",
      "loss: tensor(0.0402, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.252\n",
      "pnl: 0.015\n",
      "inv reward: -0.267\n",
      "inventors: -367\n",
      "loss: tensor(0.0099, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.18905\n",
      "pnl: -0.00555\n",
      "inv reward: -0.1835\n",
      "inventors: -330\n",
      "loss: tensor(1.3404, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.33\n",
      "pnl: 0\n",
      "inv reward: 0.33\n",
      "inventors: -330\n",
      "loss: tensor(0.0263, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.995\n",
      "pnl: 0.004999999999999999\n",
      "inv reward: 0.99\n",
      "inventors: -230\n",
      "loss: tensor(2.1845, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.11155000000000001\n",
      "pnl: -0.00345\n",
      "inv reward: 0.115\n",
      "inventors: -207\n",
      "loss: tensor(0.0037, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1035\n",
      "pnl: 0\n",
      "inv reward: 0.1035\n",
      "inventors: -207\n",
      "loss: tensor(0.0007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.207\n",
      "pnl: 0\n",
      "inv reward: -0.207\n",
      "inventors: -207\n",
      "loss: tensor(1.3056, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.207\n",
      "pnl: 0\n",
      "inv reward: 0.207\n",
      "inventors: -207\n",
      "loss: tensor(0.6858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1035\n",
      "pnl: 0\n",
      "inv reward: 0.1035\n",
      "inventors: -207\n",
      "loss: tensor(0.0010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -207\n",
      "loss: tensor(0.4577, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -207\n",
      "loss: tensor(0.8519, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4563\n",
      "pnl: 0.0423\n",
      "inv reward: 0.414\n",
      "inventors: -113\n",
      "loss: tensor(0.1414, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.057100000000000005\n",
      "pnl: -0.0006\n",
      "inv reward: -0.0565\n",
      "inventors: -101\n",
      "loss: tensor(0.5510, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0505\n",
      "pnl: 0\n",
      "inv reward: 0.0505\n",
      "inventors: -101\n",
      "loss: tensor(1.2914, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -101\n",
      "loss: tensor(0.2023, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.051050000000000005\n",
      "pnl: 0.00055\n",
      "inv reward: 0.0505\n",
      "inventors: -90\n",
      "loss: tensor(0.0145, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.30500000000000005\n",
      "pnl: 0.035\n",
      "inv reward: 0.27\n",
      "inventors: 10\n",
      "loss: tensor(1.6683, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 10\n",
      "loss: tensor(0.0018, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.015\n",
      "pnl: 0\n",
      "inv reward: -0.015\n",
      "inventors: 10\n",
      "loss: tensor(0.2400, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.01\n",
      "pnl: 0\n",
      "inv reward: -0.01\n",
      "inventors: 10\n",
      "loss: tensor(0.7553, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0025\n",
      "pnl: 0\n",
      "inv reward: 0.0025\n",
      "inventors: 10\n",
      "loss: tensor(0.0271, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0207\n",
      "pnl: 0.0132\n",
      "inv reward: 0.0075\n",
      "inventors: 76\n",
      "loss: tensor(1.8302, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.249\n",
      "pnl: 0.055\n",
      "inv reward: -0.304\n",
      "inventors: 176\n",
      "loss: tensor(0.5007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 176\n",
      "loss: tensor(0.1210, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.396\n",
      "pnl: 0\n",
      "inv reward: 0.396\n",
      "inventors: 176\n",
      "loss: tensor(2.2441, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.396\n",
      "pnl: 0\n",
      "inv reward: -0.396\n",
      "inventors: 176\n",
      "loss: tensor(0.4631, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.088\n",
      "pnl: 0\n",
      "inv reward: -0.088\n",
      "inventors: 176\n",
      "loss: tensor(1.8307, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.307\n",
      "pnl: 0.045\n",
      "inv reward: -0.352\n",
      "inventors: 276\n",
      "loss: tensor(0.5384, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.12630000000000002\n",
      "pnl: 0.0117\n",
      "inv reward: -0.138\n",
      "inventors: 354\n",
      "loss: tensor(1.3364, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.177\n",
      "pnl: 0\n",
      "inv reward: -0.177\n",
      "inventors: 354\n",
      "loss: tensor(0.8778, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.33749999999999997\n",
      "pnl: 0.0165\n",
      "inv reward: -0.354\n",
      "inventors: 420\n",
      "loss: tensor(0.4881, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.8080999999999998\n",
      "pnl: -0.0231\n",
      "inv reward: -1.785\n",
      "inventors: 378\n",
      "loss: tensor(0.0833, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.8065\n",
      "pnl: 0.044\n",
      "inv reward: -0.8505\n",
      "inventors: 466\n",
      "loss: tensor(1.3806, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9314\n",
      "pnl: 0.0006\n",
      "inv reward: -0.932\n",
      "inventors: 478\n",
      "loss: tensor(0.1444, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.6819999999999999\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: -0.717\n",
      "inventors: 578\n",
      "loss: tensor(0.0259, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.27599999999999997\n",
      "pnl: 0.013\n",
      "inv reward: -0.289\n",
      "inventors: 630\n",
      "loss: tensor(2.9623, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.89\n",
      "pnl: 0\n",
      "inv reward: -1.89\n",
      "inventors: 630\n",
      "loss: tensor(2.5255, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1575\n",
      "pnl: 0\n",
      "inv reward: 0.1575\n",
      "inventors: 630\n",
      "loss: tensor(0.0888, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4725\n",
      "pnl: 0\n",
      "inv reward: -0.4725\n",
      "inventors: 630\n",
      "loss: tensor(1.0176, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.1025\n",
      "pnl: 0\n",
      "inv reward: -1.1025\n",
      "inventors: 630\n",
      "loss: tensor(0.6295, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.7559\n",
      "pnl: -0.0234\n",
      "inv reward: -1.7325\n",
      "inventors: 567\n",
      "loss: tensor(0.1243, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.85335\n",
      "pnl: -0.00285\n",
      "inv reward: -0.8505\n",
      "inventors: 510\n",
      "loss: tensor(0.0608, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.02\n",
      "pnl: 0\n",
      "inv reward: -1.02\n",
      "inventors: 510\n",
      "loss: tensor(0.5848, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7551\n",
      "pnl: 0.0099\n",
      "inv reward: -0.765\n",
      "inventors: 532\n",
      "loss: tensor(0.3638, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9640000000000001\n",
      "pnl: 0.1\n",
      "inv reward: -1.064\n",
      "inventors: 532\n",
      "loss: tensor(0.1843, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.394\n",
      "pnl: 0\n",
      "inv reward: 2.394\n",
      "inventors: 532\n",
      "loss: tensor(2.3363, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.394\n",
      "pnl: 0\n",
      "inv reward: -2.394\n",
      "inventors: 532\n",
      "loss: tensor(0.4057, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 532\n",
      "loss: tensor(0.0785, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.21600000000000003\n",
      "pnl: 0.05\n",
      "inv reward: -0.266\n",
      "inventors: 532\n",
      "loss: tensor(0.1029, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 532\n",
      "loss: tensor(1.7998, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.9500000000000002\n",
      "pnl: 0.045\n",
      "inv reward: -1.995\n",
      "inventors: 632\n",
      "loss: tensor(0.1046, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.264\n",
      "pnl: 0\n",
      "inv reward: 1.264\n",
      "inventors: 632\n",
      "loss: tensor(0.7033, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 632\n",
      "loss: tensor(0.8189, grad_fn=<SmoothL1LossBackward>)\n",
      "Epsiode 0 | step 780 | reward -66.30995000000001 | loss 578.9339356709281\n",
      "100%|██████████| 1/1 [01:10<00:00, 70.16s/it]\n",
      "tensor([[ 0.4474,  0.0265, -0.0652,  0.0518,  0.0790, -0.0434,  0.0119,  0.2687,\n",
      "          0.0608,  0.0158,  0.0240, -0.0975, -0.1210, -0.1116, -0.0525,  0.4232,\n",
      "         -0.3545, -0.3223,  0.0737,  0.1014, -0.0321, -0.0255, -0.1442,  0.0489,\n",
      "          0.1691, -0.1620,  0.0277, -0.0981,  0.0147, -0.2066,  0.0609,  0.2507,\n",
      "         -0.1820,  0.0592,  0.0709, -0.1579, -0.1968, -0.0782,  0.0112,  0.1204,\n",
      "          0.0952, -0.1684,  0.2269, -0.1639, -0.0223, -0.1610, -0.0314,  0.0828,\n",
      "          0.0269,  0.1704, -0.0022, -0.0951, -0.0794,  0.1578,  0.0193,  0.0490]])\n"
     ]
    }
   ],
   "source": [
    "episodes = 250\n",
    "lr = 0.0005\n",
    "window_length = 30\n",
    "eps = 0.9\n",
    "eps_decay = utils.linear_decay(epochs=170000, start=eps, end=0.001)\n",
    "\n",
    "sigpolicy = SigPolicy(env, 3)\n",
    "sigpolicy.initialize_parameters(zero_bias=True)\n",
    "print(sigpolicy.linear.weight.data)\n",
    "\n",
    "results = train(env, \n",
    "                sigpolicy, \n",
    "                episodes, \n",
    "                learning_rate=lr, \n",
    "                epsilon=eps,\n",
    "                epsilon_decay=eps_decay,\n",
    "                window_length=window_length, \n",
    "                printing=False)\n",
    "\n",
    "print(sigpolicy.linear.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[\"actions\"][15])\n",
    "#plt.plot([reward if reward < 50000 else 500 for reward in results[\"rewards\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
