{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run base.ipynb\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abides_gym_market_making_environment import *\n",
    "from policies import SigPolicy\n",
    "from train import train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register market making env for gym use \n",
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id=\"market-making-v0\",\n",
    "    entry_point=SubGymMarketsMarketMakingEnv_v0,\n",
    ")\n",
    "\n",
    "def generate_env(seed):\n",
    "    \"\"\"\n",
    "    generates specific environment with the parameters defined and set the seed\n",
    "    \"\"\"\n",
    "    env = gym.make(\n",
    "            \"market-making-v0\",\n",
    "            background_config=\"rmsc04\",\n",
    "            mkt_close=\"11:45:00\",\n",
    "            timestep_duration=\"10s\",\n",
    "            order_fixed_size=100,\n",
    "            first_intervall=\"00:10:00\"\n",
    "            max_inventory=1000,\n",
    "            remaining_inventory_reward=-100,#penalty\n",
    "            inventory_reward_dampener=0.6,\n",
    "            damp_mode=\"asymmetric\",\n",
    "            debug_mode=False\n",
    "        )\n",
    "\n",
    "    env.seed(seed)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the environment\n",
    "env = generate_env(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0344, -0.0125, -0.0316,  0.0688, -0.0874,  0.1141, -0.1234, -0.1059,\n",
      "          0.0409,  0.0752,  0.0696,  0.0223,  0.0550,  0.0975,  0.0738,  0.0363,\n",
      "         -0.0550, -0.0853, -0.0376, -0.0317,  0.1070,  0.0412, -0.0537, -0.0913,\n",
      "         -0.0525,  0.0435,  0.1151,  0.1326,  0.0104, -0.0813, -0.0876,  0.1248,\n",
      "         -0.0902,  0.0607, -0.0273, -0.0496,  0.1155,  0.0834, -0.0300, -0.0107,\n",
      "          0.0767, -0.0468, -0.0970,  0.0199, -0.1108,  0.0470,  0.0101, -0.0060,\n",
      "         -0.0172, -0.0325,  0.0183,  0.0323, -0.0201, -0.1129, -0.0350, -0.0997]])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0316, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.5867, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0102, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0054, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0001, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 0\n",
      "loss: tensor(0.0229, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.025\n",
      "pnl: 0.025\n",
      "inv reward: 0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.0587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.025\n",
      "pnl: 0\n",
      "inv reward: 0.025\n",
      "inventors: -100\n",
      "loss: tensor(0.0005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.0009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.1067, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.0064, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.0132, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -100\n",
      "loss: tensor(0.0026, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.05\n",
      "pnl: 0\n",
      "inv reward: 0.05\n",
      "inventors: -100\n",
      "loss: tensor(0.0084, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.05\n",
      "pnl: 0\n",
      "inv reward: -0.05\n",
      "inventors: -100\n",
      "loss: tensor(9.3022e-05, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00975\n",
      "pnl: 0.00975\n",
      "inv reward: -0.0\n",
      "inventors: -165\n",
      "loss: tensor(0.0355, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0675\n",
      "pnl: 0.015\n",
      "inv reward: -0.0825\n",
      "inventors: -265\n",
      "loss: tensor(0.0219, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.265\n",
      "pnl: 0\n",
      "inv reward: 0.265\n",
      "inventors: -265\n",
      "loss: tensor(0.0778, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -265\n",
      "loss: tensor(0.0060, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -265\n",
      "loss: tensor(0.0007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -265\n",
      "loss: tensor(0.0025, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -265\n",
      "loss: tensor(4.7020e-05, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -265\n",
      "loss: tensor(0.4698, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.265\n",
      "pnl: 0\n",
      "inv reward: -0.265\n",
      "inventors: -265\n",
      "loss: tensor(2.5123, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.33125\n",
      "pnl: 0\n",
      "inv reward: -0.33125\n",
      "inventors: -265\n",
      "loss: tensor(0.5585, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0027\n",
      "pnl: -0.0027\n",
      "inv reward: -0.0\n",
      "inventors: -238\n",
      "loss: tensor(2.1578, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0595\n",
      "pnl: 0\n",
      "inv reward: 0.0595\n",
      "inventors: -238\n",
      "loss: tensor(0.3884, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.104\n",
      "pnl: 0.015\n",
      "inv reward: -0.119\n",
      "inventors: -338\n",
      "loss: tensor(3.1908, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -338\n",
      "loss: tensor(0.2131, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015000000000000001\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.0\n",
      "inventors: -438\n",
      "loss: tensor(0.0092, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5325\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.5475\n",
      "inventors: -538\n",
      "loss: tensor(0.3271, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1345\n",
      "pnl: 0\n",
      "inv reward: 0.1345\n",
      "inventors: -538\n",
      "loss: tensor(0.9365, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.269\n",
      "pnl: 0\n",
      "inv reward: -0.269\n",
      "inventors: -538\n",
      "loss: tensor(0.0762, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.553\n",
      "pnl: 0.015\n",
      "inv reward: 0.538\n",
      "inventors: -438\n",
      "loss: tensor(0.7484, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.23399999999999999\n",
      "pnl: 0.015\n",
      "inv reward: 0.219\n",
      "inventors: -338\n",
      "loss: tensor(0.1898, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.169\n",
      "pnl: 0\n",
      "inv reward: 0.169\n",
      "inventors: -338\n",
      "loss: tensor(0.0104, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.169\n",
      "pnl: 0\n",
      "inv reward: 0.169\n",
      "inventors: -338\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015000000000000001\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.0\n",
      "inventors: -238\n",
      "loss: tensor(0.0484, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.62\n",
      "pnl: 0.025\n",
      "inv reward: 0.595\n",
      "inventors: -138\n",
      "loss: tensor(0.7075, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.17055\n",
      "pnl: 0.03255\n",
      "inv reward: 0.138\n",
      "inventors: -45\n",
      "loss: tensor(2.2686, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -45\n",
      "loss: tensor(3.4563, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.20375000000000001\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: 0.16875\n",
      "inventors: 55\n",
      "loss: tensor(1.2839, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.11230000000000001\n",
      "pnl: 0.0252\n",
      "inv reward: -0.1375\n",
      "inventors: 97\n",
      "loss: tensor(3.5654, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.097\n",
      "pnl: 0\n",
      "inv reward: 0.097\n",
      "inventors: 97\n",
      "loss: tensor(0.0042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.02425\n",
      "pnl: 0\n",
      "inv reward: -0.02425\n",
      "inventors: 97\n",
      "loss: tensor(0.8085, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.08775\n",
      "pnl: 0.015\n",
      "inv reward: 0.07275\n",
      "inventors: -3\n",
      "loss: tensor(1.3501, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -3\n",
      "loss: tensor(0.0126, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00225\n",
      "pnl: 0\n",
      "inv reward: 0.00225\n",
      "inventors: -3\n",
      "loss: tensor(2.7004, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -3\n",
      "loss: tensor(0.0034, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.003\n",
      "pnl: 0\n",
      "inv reward: -0.003\n",
      "inventors: -3\n",
      "loss: tensor(5.6382, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -3\n",
      "loss: tensor(0.0103, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01455\n",
      "pnl: 0.01305\n",
      "inv reward: 0.0015\n",
      "inventors: 84\n",
      "loss: tensor(0.0258, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.069\n",
      "pnl: 0.015\n",
      "inv reward: -0.084\n",
      "inventors: 184\n",
      "loss: tensor(0.0100, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.21500000000000002\n",
      "pnl: 0.015\n",
      "inv reward: -0.23\n",
      "inventors: 284\n",
      "loss: tensor(0.0284, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.355\n",
      "pnl: 0\n",
      "inv reward: -0.355\n",
      "inventors: 284\n",
      "loss: tensor(0.7773, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.142\n",
      "pnl: 0\n",
      "inv reward: -0.142\n",
      "inventors: 284\n",
      "loss: tensor(2.6588, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.284\n",
      "pnl: 0\n",
      "inv reward: -0.284\n",
      "inventors: 284\n",
      "loss: tensor(1.5756, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5229999999999999\n",
      "pnl: 0.045\n",
      "inv reward: -0.568\n",
      "inventors: 384\n",
      "loss: tensor(3.2398, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.26299999999999996\n",
      "pnl: 0.025\n",
      "inv reward: -0.288\n",
      "inventors: 484\n",
      "loss: tensor(0.0692, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.121\n",
      "pnl: 0\n",
      "inv reward: -0.121\n",
      "inventors: 484\n",
      "loss: tensor(4.3766, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.242\n",
      "pnl: 0\n",
      "inv reward: -0.242\n",
      "inventors: 484\n",
      "loss: tensor(5.2824, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.242\n",
      "pnl: 0\n",
      "inv reward: -0.242\n",
      "inventors: 484\n",
      "loss: tensor(3.7932, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.217\n",
      "pnl: 0.025\n",
      "inv reward: -0.242\n",
      "inventors: 584\n",
      "loss: tensor(0.3431, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5489999999999999\n",
      "pnl: 0.035\n",
      "inv reward: -0.584\n",
      "inventors: 684\n",
      "loss: tensor(0.7864, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.669\n",
      "pnl: 0.015\n",
      "inv reward: -0.684\n",
      "inventors: 784\n",
      "loss: tensor(0.5734, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 784\n",
      "loss: tensor(2.2295, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.377\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.392\n",
      "inventors: 884\n",
      "loss: tensor(1.8814, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 884\n",
      "loss: tensor(1.1536, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 884\n",
      "loss: tensor(0.0623, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 884\n",
      "loss: tensor(1.6605, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.09\n",
      "pnl: 0.015\n",
      "inv reward: -1.105\n",
      "inventors: 984\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.246\n",
      "pnl: 0\n",
      "inv reward: 0.246\n",
      "inventors: 984\n",
      "loss: tensor(0.0193, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.492\n",
      "pnl: 0\n",
      "inv reward: -0.492\n",
      "inventors: 984\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 984\n",
      "loss: tensor(3.7260, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 984\n",
      "loss: tensor(0.0053, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 984\n",
      "loss: tensor(0.1077, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.435\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: -2.46\n",
      "inventors: 1084\n",
      "loss: tensor(3.0705, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1084\n",
      "loss: tensor(0.4583, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.168\n",
      "pnl: 0\n",
      "inv reward: 2.168\n",
      "inventors: 1084\n",
      "loss: tensor(4.7744, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1084\n",
      "loss: tensor(2.6747, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1084\n",
      "loss: tensor(0.0859, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1084\n",
      "loss: tensor(3.8153, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.542\n",
      "pnl: 0\n",
      "inv reward: -0.542\n",
      "inventors: 1084\n",
      "loss: tensor(3.6390, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1084\n",
      "loss: tensor(6.3047, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00545\n",
      "pnl: -0.00545\n",
      "inv reward: 0.0\n",
      "inventors: 975\n",
      "loss: tensor(9.5537, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.055\n",
      "pnl: 0.055\n",
      "inv reward: 0.0\n",
      "inventors: 1075\n",
      "loss: tensor(6.4105, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.3\n",
      "pnl: 0\n",
      "inv reward: -4.3\n",
      "inventors: 1075\n",
      "loss: tensor(0.9288, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1075\n",
      "loss: tensor(3.3175, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1075\n",
      "loss: tensor(0.0016, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.225\n",
      "pnl: 0\n",
      "inv reward: -3.225\n",
      "inventors: 1075\n",
      "loss: tensor(5.0587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.3\n",
      "pnl: 0\n",
      "inv reward: -4.3\n",
      "inventors: 1075\n",
      "loss: tensor(4.0586, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.075\n",
      "pnl: 0\n",
      "inv reward: -1.075\n",
      "inventors: 1075\n",
      "loss: tensor(3.8237, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.26875\n",
      "pnl: 0\n",
      "inv reward: -0.26875\n",
      "inventors: 1075\n",
      "loss: tensor(0.0022, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.41875\n",
      "pnl: 0\n",
      "inv reward: 2.41875\n",
      "inventors: 1075\n",
      "loss: tensor(5.1824, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1075\n",
      "loss: tensor(0.3764, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.15\n",
      "pnl: 0\n",
      "inv reward: -2.15\n",
      "inventors: 1075\n",
      "loss: tensor(0.1144, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.80625\n",
      "pnl: 0\n",
      "inv reward: 0.80625\n",
      "inventors: 1075\n",
      "loss: tensor(0.0449, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.23515\n",
      "pnl: 0.0336\n",
      "inv reward: -0.26875\n",
      "inventors: 991\n",
      "loss: tensor(5.9580, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.9969999999999999\n",
      "pnl: 0.015\n",
      "inv reward: 1.982\n",
      "inventors: 891\n",
      "loss: tensor(14.3042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 891\n",
      "loss: tensor(6.2483, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 3.1835\n",
      "pnl: 0.065\n",
      "inv reward: 3.1185\n",
      "inventors: 791\n",
      "loss: tensor(5.9246, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.57075\n",
      "pnl: 0\n",
      "inv reward: 2.57075\n",
      "inventors: 791\n",
      "loss: tensor(0.0006, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 791\n",
      "loss: tensor(1.8366, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.423\n",
      "pnl: 0.05\n",
      "inv reward: 2.373\n",
      "inventors: 691\n",
      "loss: tensor(2.5491, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.691\n",
      "pnl: 0\n",
      "inv reward: 0.691\n",
      "inventors: 691\n",
      "loss: tensor(0.1279, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.17275\n",
      "pnl: 0\n",
      "inv reward: 0.17275\n",
      "inventors: 691\n",
      "loss: tensor(0.7583, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.17275\n",
      "pnl: 0\n",
      "inv reward: -0.17275\n",
      "inventors: 691\n",
      "loss: tensor(5.1038, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(5.6882, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.26575\n",
      "pnl: 0.02\n",
      "inv reward: 2.24575\n",
      "inventors: 591\n",
      "loss: tensor(5.5522, grad_fn=<SmoothL1LossBackward>)\n",
      "Epsiode 0 | step 200 | reward -4.40325 | loss 186.78021732818524\n",
      "reward: -1.13635\n",
      "pnl: 0.04565\n",
      "inv reward: -1.182\n",
      "inventors: 674\n",
      "loss: tensor(4.7475, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00255\n",
      "pnl: 0.00255\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(2.2412e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.0365\n",
      "pnl: 0\n",
      "inv reward: -1.0365\n",
      "inventors: 691\n",
      "loss: tensor(0.0015, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3455\n",
      "pnl: 0\n",
      "inv reward: 0.3455\n",
      "inventors: 691\n",
      "loss: tensor(0.1530, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(2.0605, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 691\n",
      "loss: tensor(2.6552, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.4684999999999997\n",
      "pnl: 0.05\n",
      "inv reward: 2.4185\n",
      "inventors: 591\n",
      "loss: tensor(9.6708, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2955\n",
      "pnl: 0\n",
      "inv reward: 0.2955\n",
      "inventors: 591\n",
      "loss: tensor(3.0645, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.8865\n",
      "pnl: 0\n",
      "inv reward: 0.8865\n",
      "inventors: 591\n",
      "loss: tensor(8.6970, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 591\n",
      "loss: tensor(13.1681, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.012\n",
      "pnl: 0.012\n",
      "inv reward: 0.0\n",
      "inventors: 639\n",
      "loss: tensor(7.1500, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3195\n",
      "pnl: 0\n",
      "inv reward: 0.3195\n",
      "inventors: 639\n",
      "loss: tensor(2.0624, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 639\n",
      "loss: tensor(3.4468, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 639\n",
      "loss: tensor(4.4897, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.639\n",
      "pnl: 0\n",
      "inv reward: 0.639\n",
      "inventors: 639\n",
      "loss: tensor(11.1334, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.68255\n",
      "pnl: 0.04355\n",
      "inv reward: 0.639\n",
      "inventors: 572\n",
      "loss: tensor(3.3132, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.286\n",
      "pnl: 0\n",
      "inv reward: 0.286\n",
      "inventors: 572\n",
      "loss: tensor(3.3325, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.40399999999999997\n",
      "pnl: 0.025\n",
      "inv reward: -0.429\n",
      "inventors: 672\n",
      "loss: tensor(19.0324, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4976\n",
      "pnl: 0.0063999999999999994\n",
      "inv reward: -0.504\n",
      "inventors: 704\n",
      "loss: tensor(7.8068, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(17.0194, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(6.9787, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(6.6294, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(13.9467, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(8.5177, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.704\n",
      "pnl: 0\n",
      "inv reward: -0.704\n",
      "inventors: 704\n",
      "loss: tensor(14.8453, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.352\n",
      "pnl: 0\n",
      "inv reward: -0.352\n",
      "inventors: 704\n",
      "loss: tensor(1.4671, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 704\n",
      "loss: tensor(6.8008, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.0310000000000001\n",
      "pnl: 0.025\n",
      "inv reward: -1.056\n",
      "inventors: 804\n",
      "loss: tensor(6.9307, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4113\n",
      "pnl: 0.0093\n",
      "inv reward: 0.402\n",
      "inventors: 866\n",
      "loss: tensor(1.6589, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 866\n",
      "loss: tensor(15.9422, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.433\n",
      "pnl: 0\n",
      "inv reward: 0.433\n",
      "inventors: 866\n",
      "loss: tensor(7.2789, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.418\n",
      "pnl: 0.015\n",
      "inv reward: -0.433\n",
      "inventors: 966\n",
      "loss: tensor(0.2762, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 966\n",
      "loss: tensor(0.1161, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.966\n",
      "pnl: 0\n",
      "inv reward: -0.966\n",
      "inventors: 966\n",
      "loss: tensor(13.7706, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.72365\n",
      "pnl: -0.0008500000000000001\n",
      "inv reward: 0.7245\n",
      "inventors: 869\n",
      "loss: tensor(11.7671, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.65175\n",
      "pnl: 0\n",
      "inv reward: -0.65175\n",
      "inventors: 869\n",
      "loss: tensor(7.7691, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.844\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: -0.869\n",
      "inventors: 969\n",
      "loss: tensor(1.0446, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 969\n",
      "loss: tensor(5.1288, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 969\n",
      "loss: tensor(11.4368, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4695\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.4845\n",
      "inventors: 1069\n",
      "loss: tensor(10.8322, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.6035\n",
      "pnl: 0\n",
      "inv reward: -1.6035\n",
      "inventors: 1069\n",
      "loss: tensor(5.8152, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1069\n",
      "loss: tensor(8.2900, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5345\n",
      "pnl: 0\n",
      "inv reward: -0.5345\n",
      "inventors: 1069\n",
      "loss: tensor(13.8477, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1069\n",
      "loss: tensor(3.2164, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5495\n",
      "pnl: 0.015\n",
      "inv reward: 0.5345\n",
      "inventors: 969\n",
      "loss: tensor(8.6225, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4995\n",
      "pnl: 0.015\n",
      "inv reward: 0.4845\n",
      "inventors: 869\n",
      "loss: tensor(0.1180, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00195\n",
      "pnl: 0.00195\n",
      "inv reward: 0.0\n",
      "inventors: 856\n",
      "loss: tensor(3.1774, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 756\n",
      "loss: tensor(1.3708, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.9329999999999998\n",
      "pnl: 0.043\n",
      "inv reward: 1.89\n",
      "inventors: 656\n",
      "loss: tensor(13.7042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 656\n",
      "loss: tensor(4.7689, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 556\n",
      "loss: tensor(4.1501, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.556\n",
      "pnl: 0\n",
      "inv reward: 0.556\n",
      "inventors: 556\n",
      "loss: tensor(3.2762, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.29300000000000004\n",
      "pnl: 0.015\n",
      "inv reward: 0.278\n",
      "inventors: 456\n",
      "loss: tensor(3.9189, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 456\n",
      "loss: tensor(3.7620, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.47900000000000004\n",
      "pnl: 0.023\n",
      "inv reward: 0.456\n",
      "inventors: 364\n",
      "loss: tensor(1.7981, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.19385\n",
      "pnl: 0.01185\n",
      "inv reward: 0.182\n",
      "inventors: 443\n",
      "loss: tensor(1.5220, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2365\n",
      "pnl: 0.015\n",
      "inv reward: 0.2215\n",
      "inventors: 343\n",
      "loss: tensor(0.1523, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1715\n",
      "pnl: 0\n",
      "inv reward: 0.1715\n",
      "inventors: 343\n",
      "loss: tensor(3.2623, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1715\n",
      "pnl: 0\n",
      "inv reward: 0.1715\n",
      "inventors: 343\n",
      "loss: tensor(2.9679, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.18560000000000001\n",
      "pnl: 0.0141\n",
      "inv reward: 0.1715\n",
      "inventors: 249\n",
      "loss: tensor(2.9543, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1242\n",
      "pnl: 0.0003\n",
      "inv reward: -0.1245\n",
      "inventors: 243\n",
      "loss: tensor(2.4585, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.11175\n",
      "pnl: 0.00975\n",
      "inv reward: -0.1215\n",
      "inventors: 308\n",
      "loss: tensor(1.3863e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.323\n",
      "pnl: 0.015\n",
      "inv reward: 0.308\n",
      "inventors: 208\n",
      "loss: tensor(3.6649, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.156\n",
      "pnl: 0\n",
      "inv reward: 0.156\n",
      "inventors: 208\n",
      "loss: tensor(10.1522, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.104\n",
      "pnl: 0\n",
      "inv reward: -0.104\n",
      "inventors: 208\n",
      "loss: tensor(6.6913, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.052\n",
      "pnl: 0\n",
      "inv reward: 0.052\n",
      "inventors: 208\n",
      "loss: tensor(7.8814, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.119\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: 0.104\n",
      "inventors: 108\n",
      "loss: tensor(5.4164, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.162\n",
      "pnl: 0\n",
      "inv reward: 0.162\n",
      "inventors: 108\n",
      "loss: tensor(0.1613, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.069\n",
      "pnl: 0.015\n",
      "inv reward: 0.054\n",
      "inventors: 8\n",
      "loss: tensor(3.5508, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.004\n",
      "pnl: 0\n",
      "inv reward: 0.004\n",
      "inventors: 8\n",
      "loss: tensor(7.2835, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.008\n",
      "pnl: 0\n",
      "inv reward: -0.008\n",
      "inventors: 8\n",
      "loss: tensor(12.0028, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.003\n",
      "pnl: 0.005\n",
      "inv reward: -0.008\n",
      "inventors: 108\n",
      "loss: tensor(2.6254, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.162\n",
      "pnl: 0\n",
      "inv reward: -0.162\n",
      "inventors: 108\n",
      "loss: tensor(4.2983, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 108\n",
      "loss: tensor(3.4329, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 108\n",
      "loss: tensor(7.0412, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.039\n",
      "pnl: 0.015\n",
      "inv reward: -0.054\n",
      "inventors: 208\n",
      "loss: tensor(1.1395, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 208\n",
      "loss: tensor(2.1687, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.416\n",
      "pnl: 0\n",
      "inv reward: -0.416\n",
      "inventors: 208\n",
      "loss: tensor(1.7603, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.52\n",
      "pnl: 0\n",
      "inv reward: -0.52\n",
      "inventors: 208\n",
      "loss: tensor(6.4209, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.31305\n",
      "pnl: -0.00105\n",
      "inv reward: -0.312\n",
      "inventors: 187\n",
      "loss: tensor(8.0676, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 187\n",
      "loss: tensor(2.3929, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 187\n",
      "loss: tensor(11.0158, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.039400000000000004\n",
      "pnl: 0.039400000000000004\n",
      "inv reward: 0.0\n",
      "inventors: 287\n",
      "loss: tensor(0.1366, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.64575\n",
      "pnl: 0\n",
      "inv reward: -0.64575\n",
      "inventors: 287\n",
      "loss: tensor(5.2872, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.07175\n",
      "pnl: 0\n",
      "inv reward: -0.07175\n",
      "inventors: 287\n",
      "loss: tensor(5.8565, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1435\n",
      "pnl: 0\n",
      "inv reward: -0.1435\n",
      "inventors: 287\n",
      "loss: tensor(0.0023, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.861\n",
      "pnl: 0\n",
      "inv reward: -0.861\n",
      "inventors: 287\n",
      "loss: tensor(3.8381, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 287\n",
      "loss: tensor(4.8270, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9894999999999999\n",
      "pnl: 0.015\n",
      "inv reward: -1.0045\n",
      "inventors: 387\n",
      "loss: tensor(11.2783, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.48375\n",
      "pnl: 0\n",
      "inv reward: 0.48375\n",
      "inventors: 387\n",
      "loss: tensor(0.9180, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.11675\n",
      "pnl: 0.02\n",
      "inv reward: 0.09675\n",
      "inventors: 287\n",
      "loss: tensor(13.9923, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1435\n",
      "pnl: 0\n",
      "inv reward: 0.1435\n",
      "inventors: 287\n",
      "loss: tensor(4.4323, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 287\n",
      "loss: tensor(0.2755, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1435\n",
      "pnl: 0\n",
      "inv reward: 0.1435\n",
      "inventors: 287\n",
      "loss: tensor(11.1865, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.14905\n",
      "pnl: 0.00555\n",
      "inv reward: 0.1435\n",
      "inventors: 250\n",
      "loss: tensor(0.7945, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1625\n",
      "pnl: 0.025\n",
      "inv reward: -0.1875\n",
      "inventors: 350\n",
      "loss: tensor(6.6687, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 350\n",
      "loss: tensor(0.2530, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0875\n",
      "pnl: 0\n",
      "inv reward: -0.0875\n",
      "inventors: 350\n",
      "loss: tensor(13.3444, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.15725\n",
      "pnl: 0.017750000000000002\n",
      "inv reward: -0.175\n",
      "inventors: 421\n",
      "loss: tensor(11.4261, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.39599999999999996\n",
      "pnl: 0.025\n",
      "inv reward: -0.421\n",
      "inventors: 521\n",
      "loss: tensor(6.6526, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.37575\n",
      "pnl: 0.015\n",
      "inv reward: -0.39075\n",
      "inventors: 621\n",
      "loss: tensor(9.4111, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9115\n",
      "pnl: 0.02\n",
      "inv reward: -0.9315\n",
      "inventors: 721\n",
      "loss: tensor(4.3295, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.90125\n",
      "pnl: 0\n",
      "inv reward: -0.90125\n",
      "inventors: 721\n",
      "loss: tensor(9.2216, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.18025\n",
      "pnl: 0\n",
      "inv reward: 0.18025\n",
      "inventors: 721\n",
      "loss: tensor(2.6585, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.90125\n",
      "pnl: 0\n",
      "inv reward: -0.90125\n",
      "inventors: 721\n",
      "loss: tensor(1.1598, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3455\n",
      "pnl: 0.015\n",
      "inv reward: -0.3605\n",
      "inventors: 821\n",
      "loss: tensor(0.3965, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.642\n",
      "pnl: 0\n",
      "inv reward: -1.642\n",
      "inventors: 821\n",
      "loss: tensor(11.4351, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 821\n",
      "loss: tensor(0.1309, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.6195\n",
      "pnl: 0.075\n",
      "inv reward: -3.6945\n",
      "inventors: 921\n",
      "loss: tensor(14.1226, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.25525000000000003\n",
      "pnl: 0.025\n",
      "inv reward: 0.23025\n",
      "inventors: 821\n",
      "loss: tensor(2.8914, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 3.07875\n",
      "pnl: 0\n",
      "inv reward: 3.07875\n",
      "inventors: 821\n",
      "loss: tensor(3.9966, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.055\n",
      "pnl: 0.055\n",
      "inv reward: 0.0\n",
      "inventors: 921\n",
      "loss: tensor(0.1500, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.85925\n",
      "pnl: 0.055\n",
      "inv reward: -3.91425\n",
      "inventors: 1021\n",
      "loss: tensor(9.4596, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.27625\n",
      "pnl: 0\n",
      "inv reward: -1.27625\n",
      "inventors: 1021\n",
      "loss: tensor(2.0793, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5105\n",
      "pnl: 0\n",
      "inv reward: 0.5105\n",
      "inventors: 1021\n",
      "loss: tensor(1.4343, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.76575\n",
      "pnl: 0\n",
      "inv reward: 0.76575\n",
      "inventors: 1021\n",
      "loss: tensor(0.4392, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.76575\n",
      "pnl: 0\n",
      "inv reward: -0.76575\n",
      "inventors: 1021\n",
      "loss: tensor(0.8959, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.8278\n",
      "pnl: -0.02005\n",
      "inv reward: -2.80775\n",
      "inventors: 918\n",
      "loss: tensor(2.4352, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 918\n",
      "loss: tensor(9.5735, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.6065\n",
      "pnl: 0\n",
      "inv reward: -1.6065\n",
      "inventors: 918\n",
      "loss: tensor(1.6516, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 918\n",
      "loss: tensor(12.4678, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 918\n",
      "loss: tensor(0.2042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 918\n",
      "loss: tensor(1.1009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.883\n",
      "pnl: 0.035\n",
      "inv reward: -0.918\n",
      "inventors: 1018\n",
      "loss: tensor(3.0020, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -3.8175\n",
      "pnl: 0\n",
      "inv reward: -3.8175\n",
      "inventors: 1018\n",
      "loss: tensor(0.7738, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.018\n",
      "pnl: 0\n",
      "inv reward: 1.018\n",
      "inventors: 1018\n",
      "loss: tensor(6.8692, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2545\n",
      "pnl: 0\n",
      "inv reward: 0.2545\n",
      "inventors: 1018\n",
      "loss: tensor(6.0502, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.018\n",
      "pnl: 0\n",
      "inv reward: -1.018\n",
      "inventors: 1018\n",
      "loss: tensor(6.7112, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.036\n",
      "pnl: 0\n",
      "inv reward: -2.036\n",
      "inventors: 1018\n",
      "loss: tensor(4.2779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1018\n",
      "loss: tensor(0.2114, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.02975\n",
      "pnl: 0.02975\n",
      "inv reward: 0.0\n",
      "inventors: 933\n",
      "loss: tensor(0.0258, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.3995\n",
      "pnl: 0\n",
      "inv reward: -1.3995\n",
      "inventors: 933\n",
      "loss: tensor(5.1052, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0337\n",
      "pnl: -0.0337\n",
      "inv reward: 0.0\n",
      "inventors: 839\n",
      "loss: tensor(15.7472, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -7.2833\n",
      "pnl: -0.1518\n",
      "inv reward: -7.1315\n",
      "inventors: 755\n",
      "loss: tensor(17.4813, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 5.43955\n",
      "pnl: -0.0342\n",
      "inv reward: 5.47375\n",
      "inventors: 679\n",
      "loss: tensor(11.3772, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -5.94125\n",
      "pnl: 0\n",
      "inv reward: -5.94125\n",
      "inventors: 679\n",
      "loss: tensor(7.7967, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.31175\n",
      "pnl: 0.105\n",
      "inv reward: 2.20675\n",
      "inventors: 579\n",
      "loss: tensor(11.1363, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.01325\n",
      "pnl: 0\n",
      "inv reward: 1.01325\n",
      "inventors: 579\n",
      "loss: tensor(2.5497, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 579\n",
      "loss: tensor(2.3070, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 579\n",
      "loss: tensor(2.5864, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.158\n",
      "pnl: 0\n",
      "inv reward: -1.158\n",
      "inventors: 579\n",
      "loss: tensor(18.9674, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.43425\n",
      "pnl: 0\n",
      "inv reward: -0.43425\n",
      "inventors: 579\n",
      "loss: tensor(10.6423, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 579\n",
      "loss: tensor(0.0201, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.60575\n",
      "pnl: 0.0135\n",
      "inv reward: 1.59225\n",
      "inventors: 552\n",
      "loss: tensor(0.7579, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.057600000000000005\n",
      "pnl: 0.057600000000000005\n",
      "inv reward: 0.0\n",
      "inventors: 652\n",
      "loss: tensor(0.6242, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.489\n",
      "pnl: 0\n",
      "inv reward: -0.489\n",
      "inventors: 652\n",
      "loss: tensor(1.2192, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.163\n",
      "pnl: 0\n",
      "inv reward: -0.163\n",
      "inventors: 652\n",
      "loss: tensor(0.9723, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6685\n",
      "pnl: 0.0165\n",
      "inv reward: 0.652\n",
      "inventors: 586\n",
      "loss: tensor(0.0126, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(0.9195, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.293\n",
      "pnl: 0\n",
      "inv reward: -0.293\n",
      "inventors: 586\n",
      "loss: tensor(11.0092, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.7325\n",
      "pnl: 0\n",
      "inv reward: 0.7325\n",
      "inventors: 586\n",
      "loss: tensor(11.0259, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.7325\n",
      "pnl: 0\n",
      "inv reward: 0.7325\n",
      "inventors: 586\n",
      "loss: tensor(14.7960, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1465\n",
      "pnl: 0\n",
      "inv reward: -0.1465\n",
      "inventors: 586\n",
      "loss: tensor(0.0944, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(1.6606, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4395\n",
      "pnl: 0\n",
      "inv reward: 0.4395\n",
      "inventors: 586\n",
      "loss: tensor(4.3124, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.586\n",
      "pnl: 0\n",
      "inv reward: -0.586\n",
      "inventors: 586\n",
      "loss: tensor(2.4570, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.758\n",
      "pnl: 0\n",
      "inv reward: 1.758\n",
      "inventors: 586\n",
      "loss: tensor(18.0918, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.172\n",
      "pnl: 0\n",
      "inv reward: -1.172\n",
      "inventors: 586\n",
      "loss: tensor(13.3930, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(13.4434, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.293\n",
      "pnl: 0\n",
      "inv reward: -0.293\n",
      "inventors: 586\n",
      "loss: tensor(2.6947, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.293\n",
      "pnl: 0\n",
      "inv reward: -0.293\n",
      "inventors: 586\n",
      "loss: tensor(0.9046, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(9.6085, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1465\n",
      "pnl: 0\n",
      "inv reward: -0.1465\n",
      "inventors: 586\n",
      "loss: tensor(1.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4395\n",
      "pnl: 0\n",
      "inv reward: -0.4395\n",
      "inventors: 586\n",
      "loss: tensor(2.9240, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(5.6013, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(1.3282, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 586\n",
      "loss: tensor(0.0123, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.586\n",
      "pnl: 0\n",
      "inv reward: 0.586\n",
      "inventors: 586\n",
      "loss: tensor(11.8672, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1415\n",
      "pnl: 0.005\n",
      "inv reward: -0.1465\n",
      "inventors: 486\n",
      "loss: tensor(12.6257, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1215\n",
      "pnl: 0\n",
      "inv reward: 0.1215\n",
      "inventors: 486\n",
      "loss: tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1215\n",
      "pnl: 0\n",
      "inv reward: -0.1215\n",
      "inventors: 486\n",
      "loss: tensor(0.8956, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1215\n",
      "pnl: 0\n",
      "inv reward: -0.1215\n",
      "inventors: 486\n",
      "loss: tensor(8.1187, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 486\n",
      "loss: tensor(10.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 486\n",
      "loss: tensor(0.5098, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.243\n",
      "pnl: 0\n",
      "inv reward: -0.243\n",
      "inventors: 486\n",
      "loss: tensor(9.0469, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3645\n",
      "pnl: 0\n",
      "inv reward: -0.3645\n",
      "inventors: 486\n",
      "loss: tensor(13.6413, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 486\n",
      "loss: tensor(15.1094, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 486\n",
      "loss: tensor(0.3254, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3493\n",
      "pnl: 0.0152\n",
      "inv reward: -0.3645\n",
      "inventors: 562\n",
      "loss: tensor(6.5223, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 662\n",
      "loss: tensor(15.8746, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 662\n",
      "loss: tensor(14.2837, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.8205\n",
      "pnl: 0\n",
      "inv reward: -1.8205\n",
      "inventors: 662\n",
      "loss: tensor(18.8739, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1655\n",
      "pnl: 0\n",
      "inv reward: -0.1655\n",
      "inventors: 662\n",
      "loss: tensor(13.2908, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 662\n",
      "loss: tensor(21.2700, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 662\n",
      "loss: tensor(5.3467, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 562\n",
      "loss: tensor(19.7864, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.29600000000000004\n",
      "pnl: 0.015\n",
      "inv reward: 0.281\n",
      "inventors: 462\n",
      "loss: tensor(2.7176, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 462\n",
      "loss: tensor(1.4700, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.58275\n",
      "pnl: 0.00525\n",
      "inv reward: 0.5775\n",
      "inventors: 447\n",
      "loss: tensor(0.0930, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.32675\n",
      "pnl: 0.0085\n",
      "inv reward: -0.33525\n",
      "inventors: 362\n",
      "loss: tensor(0.2424, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.29650000000000004\n",
      "pnl: 0.025\n",
      "inv reward: 0.2715\n",
      "inventors: 262\n",
      "loss: tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4585\n",
      "pnl: 0\n",
      "inv reward: 0.4585\n",
      "inventors: 262\n",
      "loss: tensor(6.3958, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.262\n",
      "pnl: 0\n",
      "inv reward: -0.262\n",
      "inventors: 262\n",
      "loss: tensor(4.1965, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 262\n",
      "loss: tensor(11.8516, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1715\n",
      "pnl: 0.025\n",
      "inv reward: -0.1965\n",
      "inventors: 362\n",
      "loss: tensor(0.0017, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2569\n",
      "pnl: 0.0146\n",
      "inv reward: -0.2715\n",
      "inventors: 435\n",
      "loss: tensor(1.1361, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00135\n",
      "pnl: 0.00135\n",
      "inv reward: 0.0\n",
      "inventors: 462\n",
      "loss: tensor(3.5096, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3465\n",
      "pnl: 0\n",
      "inv reward: 0.3465\n",
      "inventors: 462\n",
      "loss: tensor(20.9025, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 462\n",
      "loss: tensor(1.6153, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.3465\n",
      "pnl: 0\n",
      "inv reward: -0.3465\n",
      "inventors: 462\n",
      "loss: tensor(2.6323, grad_fn=<SmoothL1LossBackward>)\n",
      "Epsiode 0 | step 400 | reward -33.72379999999998 | loss 1374.0073862630506\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 462\n",
      "loss: tensor(0.0308, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.231\n",
      "pnl: 0\n",
      "inv reward: -0.231\n",
      "inventors: 462\n",
      "loss: tensor(2.1637, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 562\n",
      "loss: tensor(1.7059, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 562\n",
      "loss: tensor(3.3525, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 562\n",
      "loss: tensor(8.9809e-06, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00285\n",
      "pnl: -0.00285\n",
      "inv reward: 0.0\n",
      "inventors: 505\n",
      "loss: tensor(0.1096, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.63125\n",
      "pnl: 0\n",
      "inv reward: 0.63125\n",
      "inventors: 505\n",
      "loss: tensor(0.1242, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.505\n",
      "pnl: 0\n",
      "inv reward: -0.505\n",
      "inventors: 505\n",
      "loss: tensor(16.9409, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.02\n",
      "pnl: 0.02\n",
      "inv reward: 0.0\n",
      "inventors: 405\n",
      "loss: tensor(0.2628, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 405\n",
      "loss: tensor(0.0851, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.72875\n",
      "pnl: 0.02\n",
      "inv reward: 0.70875\n",
      "inventors: 305\n",
      "loss: tensor(17.1944, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 305\n",
      "loss: tensor(19.8071, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.33\n",
      "pnl: 0.025\n",
      "inv reward: 0.305\n",
      "inventors: 205\n",
      "loss: tensor(0.5686, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 205\n",
      "loss: tensor(2.8784, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 305\n",
      "loss: tensor(7.5747, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.51125\n",
      "pnl: 0.0225\n",
      "inv reward: -0.53375\n",
      "inventors: 405\n",
      "loss: tensor(10.3248, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 405\n",
      "loss: tensor(13.1527, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.68875\n",
      "pnl: 0.02\n",
      "inv reward: -0.70875\n",
      "inventors: 505\n",
      "loss: tensor(12.3228, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7575\n",
      "pnl: 0\n",
      "inv reward: -0.7575\n",
      "inventors: 505\n",
      "loss: tensor(21.1183, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7124999999999999\n",
      "pnl: 0.045\n",
      "inv reward: -0.7575\n",
      "inventors: 605\n",
      "loss: tensor(0.5791, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.175\n",
      "pnl: 0.035\n",
      "inv reward: -1.21\n",
      "inventors: 705\n",
      "loss: tensor(17.4038, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.52875\n",
      "pnl: 0\n",
      "inv reward: 0.52875\n",
      "inventors: 705\n",
      "loss: tensor(15.1655, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 705\n",
      "loss: tensor(0.0372, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.17625\n",
      "pnl: 0\n",
      "inv reward: 0.17625\n",
      "inventors: 705\n",
      "loss: tensor(2.2669, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 705\n",
      "loss: tensor(6.6628, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.33749999999999997\n",
      "pnl: 0.015\n",
      "inv reward: -0.3525\n",
      "inventors: 805\n",
      "loss: tensor(16.1012, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 805\n",
      "loss: tensor(0.0134, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4025\n",
      "pnl: 0\n",
      "inv reward: -0.4025\n",
      "inventors: 805\n",
      "loss: tensor(2.0739, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.1825\n",
      "pnl: 0.025\n",
      "inv reward: -1.2075\n",
      "inventors: 905\n",
      "loss: tensor(0.8240, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.13125\n",
      "pnl: 0\n",
      "inv reward: -1.13125\n",
      "inventors: 905\n",
      "loss: tensor(2.0512, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 905\n",
      "loss: tensor(8.9358, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.58375\n",
      "pnl: 0\n",
      "inv reward: 1.58375\n",
      "inventors: 905\n",
      "loss: tensor(7.6963, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015000000000000001\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: 0.0\n",
      "inventors: 1005\n",
      "loss: tensor(0.9362, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1005\n",
      "loss: tensor(8.0289, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1005\n",
      "loss: tensor(2.5855, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.5075\n",
      "pnl: 0\n",
      "inv reward: -1.5075\n",
      "inventors: 1005\n",
      "loss: tensor(16.2064, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.5125\n",
      "pnl: 0\n",
      "inv reward: -2.5125\n",
      "inventors: 1005\n",
      "loss: tensor(0.5675, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.5125\n",
      "pnl: 0\n",
      "inv reward: 2.5125\n",
      "inventors: 1005\n",
      "loss: tensor(26.3865, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.5075\n",
      "pnl: 0\n",
      "inv reward: -1.5075\n",
      "inventors: 1005\n",
      "loss: tensor(1.6953, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.25125\n",
      "pnl: 0\n",
      "inv reward: -0.25125\n",
      "inventors: 1005\n",
      "loss: tensor(3.0858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.75375\n",
      "pnl: 0\n",
      "inv reward: -0.75375\n",
      "inventors: 1005\n",
      "loss: tensor(10.9224, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.025\n",
      "pnl: 0.025\n",
      "inv reward: 0.0\n",
      "inventors: 905\n",
      "loss: tensor(10.1166, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.905\n",
      "pnl: 0\n",
      "inv reward: 0.905\n",
      "inventors: 905\n",
      "loss: tensor(9.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0063\n",
      "pnl: 0.0063\n",
      "inv reward: 0.0\n",
      "inventors: 947\n",
      "loss: tensor(6.9031, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0087\n",
      "pnl: 0.0087\n",
      "inv reward: 0.0\n",
      "inventors: 1005\n",
      "loss: tensor(2.6032, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.25125\n",
      "pnl: 0\n",
      "inv reward: -0.25125\n",
      "inventors: 1005\n",
      "loss: tensor(15.0806, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1005\n",
      "loss: tensor(0.0563, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.75375\n",
      "pnl: 0\n",
      "inv reward: -0.75375\n",
      "inventors: 1005\n",
      "loss: tensor(13.2909, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.01\n",
      "pnl: 0\n",
      "inv reward: -2.01\n",
      "inventors: 1005\n",
      "loss: tensor(16.2393, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.005\n",
      "pnl: 0\n",
      "inv reward: 1.005\n",
      "inventors: 1005\n",
      "loss: tensor(3.1568, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.77375\n",
      "pnl: 0\n",
      "inv reward: -4.77375\n",
      "inventors: 1005\n",
      "loss: tensor(7.7997, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.79875\n",
      "pnl: 0.04\n",
      "inv reward: 1.75875\n",
      "inventors: 905\n",
      "loss: tensor(4.6954, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 905\n",
      "loss: tensor(0.9173, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.905\n",
      "pnl: 0\n",
      "inv reward: 0.905\n",
      "inventors: 905\n",
      "loss: tensor(1.2587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 905\n",
      "loss: tensor(1.7766, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.22625\n",
      "pnl: 0\n",
      "inv reward: 0.22625\n",
      "inventors: 905\n",
      "loss: tensor(1.3042, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 905\n",
      "loss: tensor(1.3738, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.66415\n",
      "pnl: 0.014599999999999998\n",
      "inv reward: -0.67875\n",
      "inventors: 978\n",
      "loss: tensor(17.2692, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.23475\n",
      "pnl: 0.00975\n",
      "inv reward: -0.2445\n",
      "inventors: 1043\n",
      "loss: tensor(12.9236, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5044\n",
      "pnl: 0.0171\n",
      "inv reward: -0.5215\n",
      "inventors: 986\n",
      "loss: tensor(4.9012, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2465\n",
      "pnl: 0\n",
      "inv reward: 0.2465\n",
      "inventors: 986\n",
      "loss: tensor(10.8993, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 986\n",
      "loss: tensor(25.2841, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.479\n",
      "pnl: 0\n",
      "inv reward: -1.479\n",
      "inventors: 986\n",
      "loss: tensor(4.2359, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.508\n",
      "pnl: 0.015\n",
      "inv reward: 0.493\n",
      "inventors: 886\n",
      "loss: tensor(0.6635, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4472\n",
      "pnl: 0.004200000000000001\n",
      "inv reward: 0.443\n",
      "inventors: 858\n",
      "loss: tensor(4.1574, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 858\n",
      "loss: tensor(19.2266, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.429\n",
      "pnl: 0\n",
      "inv reward: -0.429\n",
      "inventors: 858\n",
      "loss: tensor(13.1302, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6435\n",
      "pnl: 0\n",
      "inv reward: 0.6435\n",
      "inventors: 858\n",
      "loss: tensor(16.4829, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2145\n",
      "pnl: 0\n",
      "inv reward: 0.2145\n",
      "inventors: 858\n",
      "loss: tensor(9.1521, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1995\n",
      "pnl: 0.015\n",
      "inv reward: -0.2145\n",
      "inventors: 958\n",
      "loss: tensor(1.6463, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2395\n",
      "pnl: 0\n",
      "inv reward: 0.2395\n",
      "inventors: 958\n",
      "loss: tensor(12.9629, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 958\n",
      "loss: tensor(9.7060, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.4049\n",
      "pnl: 0.0099\n",
      "inv reward: 2.395\n",
      "inventors: 940\n",
      "loss: tensor(3.6496, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.4141\n",
      "pnl: 0.0041\n",
      "inv reward: 1.41\n",
      "inventors: 858\n",
      "loss: tensor(5.8013, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.429\n",
      "pnl: 0\n",
      "inv reward: -0.429\n",
      "inventors: 858\n",
      "loss: tensor(1.6764, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 858\n",
      "loss: tensor(25.2623, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.843\n",
      "pnl: 0.015\n",
      "inv reward: -0.858\n",
      "inventors: 958\n",
      "loss: tensor(0.6481, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 958\n",
      "loss: tensor(11.0072, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.6315000000000002\n",
      "pnl: 0.045\n",
      "inv reward: -1.6765\n",
      "inventors: 1058\n",
      "loss: tensor(8.4780, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7935\n",
      "pnl: 0\n",
      "inv reward: -0.7935\n",
      "inventors: 1058\n",
      "loss: tensor(23.8437, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1058\n",
      "loss: tensor(2.6282, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.7935\n",
      "pnl: 0\n",
      "inv reward: 0.7935\n",
      "inventors: 1058\n",
      "loss: tensor(24.3882, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1058\n",
      "loss: tensor(1.5656, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2645\n",
      "pnl: 0\n",
      "inv reward: 0.2645\n",
      "inventors: 1058\n",
      "loss: tensor(5.4344, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1058\n",
      "loss: tensor(17.5434, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.529\n",
      "pnl: 0\n",
      "inv reward: -0.529\n",
      "inventors: 1058\n",
      "loss: tensor(17.0962, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1058\n",
      "loss: tensor(0.1596, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.529\n",
      "pnl: 0\n",
      "inv reward: 0.529\n",
      "inventors: 1058\n",
      "loss: tensor(0.7962, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1058\n",
      "loss: tensor(8.2207, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.058\n",
      "pnl: 0\n",
      "inv reward: -1.058\n",
      "inventors: 1058\n",
      "loss: tensor(2.6337, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.587\n",
      "pnl: 0\n",
      "inv reward: -1.587\n",
      "inventors: 1058\n",
      "loss: tensor(1.1447, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.7939999999999999\n",
      "pnl: 0.0005\n",
      "inv reward: 0.7935\n",
      "inventors: 1056\n",
      "loss: tensor(0.0171, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.779\n",
      "pnl: -0.013000000000000001\n",
      "inv reward: 0.792\n",
      "inventors: 950\n",
      "loss: tensor(5.7819, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.475\n",
      "pnl: 0\n",
      "inv reward: 0.475\n",
      "inventors: 950\n",
      "loss: tensor(0.9800, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 950\n",
      "loss: tensor(12.5295, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2375\n",
      "pnl: 0\n",
      "inv reward: 0.2375\n",
      "inventors: 950\n",
      "loss: tensor(21.7516, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 950\n",
      "loss: tensor(7.4402, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.03\n",
      "pnl: 0.03\n",
      "inv reward: 0.0\n",
      "inventors: 1050\n",
      "loss: tensor(11.7294, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2625\n",
      "pnl: 0\n",
      "inv reward: -0.2625\n",
      "inventors: 1050\n",
      "loss: tensor(2.6995, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.575\n",
      "pnl: 0\n",
      "inv reward: -1.575\n",
      "inventors: 1050\n",
      "loss: tensor(13.0777, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.525\n",
      "pnl: 0\n",
      "inv reward: -0.525\n",
      "inventors: 1050\n",
      "loss: tensor(2.7112, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2625\n",
      "pnl: 0\n",
      "inv reward: 0.2625\n",
      "inventors: 1050\n",
      "loss: tensor(0.1467, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7875\n",
      "pnl: 0\n",
      "inv reward: -0.7875\n",
      "inventors: 1050\n",
      "loss: tensor(19.3578, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.575\n",
      "pnl: 0\n",
      "inv reward: 1.575\n",
      "inventors: 1050\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1050\n",
      "loss: tensor(0.0181, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.085\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: 1.05\n",
      "inventors: 950\n",
      "loss: tensor(0.2659, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.95\n",
      "pnl: 0\n",
      "inv reward: 0.95\n",
      "inventors: 950\n",
      "loss: tensor(16.4469, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.475\n",
      "pnl: 0\n",
      "inv reward: -0.475\n",
      "inventors: 950\n",
      "loss: tensor(4.0247, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 950\n",
      "loss: tensor(23.0939, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 950\n",
      "loss: tensor(14.4618, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.48055\n",
      "pnl: 0.00555\n",
      "inv reward: 0.475\n",
      "inventors: 913\n",
      "loss: tensor(0.0393, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00315\n",
      "pnl: 0.00315\n",
      "inv reward: 0.0\n",
      "inventors: 850\n",
      "loss: tensor(0.0058, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.6625\n",
      "pnl: 0.025\n",
      "inv reward: 0.6375\n",
      "inventors: 750\n",
      "loss: tensor(2.2299, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5625\n",
      "pnl: 0\n",
      "inv reward: 0.5625\n",
      "inventors: 750\n",
      "loss: tensor(4.5009, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.36\n",
      "pnl: 0.015\n",
      "inv reward: -0.375\n",
      "inventors: 850\n",
      "loss: tensor(0.0056, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.425\n",
      "pnl: 0\n",
      "inv reward: -0.425\n",
      "inventors: 850\n",
      "loss: tensor(8.7102, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 850\n",
      "loss: tensor(15.8089, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 850\n",
      "loss: tensor(14.4382, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.85\n",
      "pnl: 0\n",
      "inv reward: -0.85\n",
      "inventors: 850\n",
      "loss: tensor(23.3200, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.85\n",
      "pnl: 0\n",
      "inv reward: 0.85\n",
      "inventors: 850\n",
      "loss: tensor(2.6175, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.85\n",
      "pnl: 0\n",
      "inv reward: -0.85\n",
      "inventors: 850\n",
      "loss: tensor(7.5904, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.7229999999999999\n",
      "pnl: 0.023\n",
      "inv reward: 1.7\n",
      "inventors: 750\n",
      "loss: tensor(15.6300, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5625\n",
      "pnl: 0\n",
      "inv reward: -0.5625\n",
      "inventors: 750\n",
      "loss: tensor(1.5348, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5625\n",
      "pnl: 0\n",
      "inv reward: 0.5625\n",
      "inventors: 750\n",
      "loss: tensor(4.1588, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 750\n",
      "loss: tensor(6.8177, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 750\n",
      "loss: tensor(25.8367, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 750\n",
      "loss: tensor(0.4200, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.75\n",
      "pnl: 0\n",
      "inv reward: -0.75\n",
      "inventors: 750\n",
      "loss: tensor(15.1957, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.39\n",
      "pnl: 0.015\n",
      "inv reward: 0.375\n",
      "inventors: 650\n",
      "loss: tensor(14.4926, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.31\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.325\n",
      "inventors: 750\n",
      "loss: tensor(8.5376, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.764\n",
      "pnl: 0.014\n",
      "inv reward: 0.75\n",
      "inventors: 694\n",
      "loss: tensor(22.6491, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.347\n",
      "pnl: 0\n",
      "inv reward: 0.347\n",
      "inventors: 694\n",
      "loss: tensor(9.6404, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1735\n",
      "pnl: 0\n",
      "inv reward: 0.1735\n",
      "inventors: 694\n",
      "loss: tensor(0.2430, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1735\n",
      "pnl: 0\n",
      "inv reward: 0.1735\n",
      "inventors: 694\n",
      "loss: tensor(4.7621, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.35059999999999997\n",
      "pnl: 0.0036\n",
      "inv reward: 0.347\n",
      "inventors: 670\n",
      "loss: tensor(5.6084, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5025\n",
      "pnl: 0\n",
      "inv reward: 0.5025\n",
      "inventors: 670\n",
      "loss: tensor(10.6331, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 670\n",
      "loss: tensor(0.1693, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5025\n",
      "pnl: 0\n",
      "inv reward: -0.5025\n",
      "inventors: 670\n",
      "loss: tensor(0.3312, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.67035\n",
      "pnl: 0.00035\n",
      "inv reward: 0.67\n",
      "inventors: 669\n",
      "loss: tensor(20.3173, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00475\n",
      "pnl: 0.00475\n",
      "inv reward: 0.0\n",
      "inventors: 688\n",
      "loss: tensor(16.8271, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.6695\n",
      "pnl: 0.0185\n",
      "inv reward: -0.688\n",
      "inventors: 762\n",
      "loss: tensor(17.3373, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.37125\n",
      "pnl: 0.00975\n",
      "inv reward: -0.381\n",
      "inventors: 827\n",
      "loss: tensor(13.4685, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.00415\n",
      "pnl: -0.00415\n",
      "inv reward: 0.0\n",
      "inventors: 744\n",
      "loss: tensor(33.2438, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.86\n",
      "pnl: 0\n",
      "inv reward: -1.86\n",
      "inventors: 744\n",
      "loss: tensor(0.2265, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 744\n",
      "loss: tensor(30.8241, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.372\n",
      "pnl: 0\n",
      "inv reward: -0.372\n",
      "inventors: 744\n",
      "loss: tensor(27.5582, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.116\n",
      "pnl: 0\n",
      "inv reward: -1.116\n",
      "inventors: 744\n",
      "loss: tensor(1.3128, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.034999999999999996\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: 0.0\n",
      "inventors: 844\n",
      "loss: tensor(11.2585, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 844\n",
      "loss: tensor(31.1021, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.6682\n",
      "pnl: 0.019799999999999998\n",
      "inv reward: -1.688\n",
      "inventors: 944\n",
      "loss: tensor(1.9573, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.71275\n",
      "pnl: -0.00475\n",
      "inv reward: -0.708\n",
      "inventors: 849\n",
      "loss: tensor(7.3010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 849\n",
      "loss: tensor(7.4416, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -4.78585\n",
      "pnl: 0.0959\n",
      "inv reward: -4.88175\n",
      "inventors: 949\n",
      "loss: tensor(5.3681, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.949\n",
      "pnl: 0\n",
      "inv reward: 0.949\n",
      "inventors: 949\n",
      "loss: tensor(0.0263, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4745\n",
      "pnl: 0\n",
      "inv reward: -0.4745\n",
      "inventors: 949\n",
      "loss: tensor(15.7260, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.4235\n",
      "pnl: 0\n",
      "inv reward: 1.4235\n",
      "inventors: 949\n",
      "loss: tensor(0.0005, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 949\n",
      "loss: tensor(17.1767, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.9339999999999999\n",
      "pnl: 0.015\n",
      "inv reward: -0.949\n",
      "inventors: 1049\n",
      "loss: tensor(3.2228, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.6225\n",
      "pnl: 0\n",
      "inv reward: 2.6225\n",
      "inventors: 1049\n",
      "loss: tensor(16.8718, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.26225\n",
      "pnl: 0\n",
      "inv reward: -0.26225\n",
      "inventors: 1049\n",
      "loss: tensor(13.3363, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.31125\n",
      "pnl: 0\n",
      "inv reward: -1.31125\n",
      "inventors: 1049\n",
      "loss: tensor(25.8197, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5245\n",
      "pnl: 0\n",
      "inv reward: 0.5245\n",
      "inventors: 1049\n",
      "loss: tensor(25.9504, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.88475\n",
      "pnl: 0\n",
      "inv reward: -2.88475\n",
      "inventors: 1049\n",
      "loss: tensor(31.7068, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.26225\n",
      "pnl: 0\n",
      "inv reward: 0.26225\n",
      "inventors: 1049\n",
      "loss: tensor(0.2633, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.1229999999999998\n",
      "pnl: 0.024999999999999998\n",
      "inv reward: 2.098\n",
      "inventors: 949\n",
      "loss: tensor(35.6212, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 949\n",
      "loss: tensor(33.0679, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.6717499999999998\n",
      "pnl: 0.011\n",
      "inv reward: 1.66075\n",
      "inventors: 929\n",
      "loss: tensor(0.3458, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.4485\n",
      "pnl: 0.016\n",
      "inv reward: -0.4645\n",
      "inventors: 849\n",
      "loss: tensor(14.7831, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.48575\n",
      "pnl: 0\n",
      "inv reward: 1.48575\n",
      "inventors: 849\n",
      "loss: tensor(7.0164, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 849\n",
      "loss: tensor(31.9819, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4395\n",
      "pnl: 0.015\n",
      "inv reward: 0.4245\n",
      "inventors: 789\n",
      "loss: tensor(0.0008, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.60675\n",
      "pnl: 0.015\n",
      "inv reward: 0.59175\n",
      "inventors: 689\n",
      "loss: tensor(0.0136, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 689\n",
      "loss: tensor(6.6196, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.51675\n",
      "pnl: 0\n",
      "inv reward: -0.51675\n",
      "inventors: 689\n",
      "loss: tensor(34.6886, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.86125\n",
      "pnl: 0\n",
      "inv reward: 0.86125\n",
      "inventors: 689\n",
      "loss: tensor(10.1497, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.5002499999999999\n",
      "pnl: 0.05\n",
      "inv reward: -1.55025\n",
      "inventors: 789\n",
      "loss: tensor(10.0131, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 789\n",
      "loss: tensor(0.2890, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.59175\n",
      "pnl: 0\n",
      "inv reward: 0.59175\n",
      "inventors: 789\n",
      "loss: tensor(21.0351, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 789\n",
      "loss: tensor(21.5984, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.9998499999999999\n",
      "pnl: 0.013600000000000001\n",
      "inv reward: 0.98625\n",
      "inventors: 755\n",
      "loss: tensor(12.3276, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 755\n",
      "loss: tensor(28.3983, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3775\n",
      "pnl: 0\n",
      "inv reward: 0.3775\n",
      "inventors: 755\n",
      "loss: tensor(37.9587, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.755\n",
      "pnl: 0\n",
      "inv reward: 0.755\n",
      "inventors: 755\n",
      "loss: tensor(0.1225, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.57825\n",
      "pnl: 0.012\n",
      "inv reward: 0.56625\n",
      "inventors: 707\n",
      "loss: tensor(12.9950, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0052\n",
      "pnl: 0.0052\n",
      "inv reward: 0.0\n",
      "inventors: 655\n",
      "loss: tensor(0.0010, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.31\n",
      "pnl: 0\n",
      "inv reward: 1.31\n",
      "inventors: 655\n",
      "loss: tensor(14.7140, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.83875\n",
      "pnl: 0.02\n",
      "inv reward: 0.81875\n",
      "inventors: 555\n",
      "loss: tensor(2.2747, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 555\n",
      "loss: tensor(0.3590, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.67875\n",
      "pnl: 0.015\n",
      "inv reward: -0.69375\n",
      "inventors: 655\n",
      "loss: tensor(7.6772, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5104500000000001\n",
      "pnl: -0.019200000000000002\n",
      "inv reward: -0.49125\n",
      "inventors: 589\n",
      "loss: tensor(10.0304, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.589\n",
      "pnl: 0\n",
      "inv reward: -0.589\n",
      "inventors: 589\n",
      "loss: tensor(20.9995, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5630499999999999\n",
      "pnl: -0.02595\n",
      "inv reward: 0.589\n",
      "inventors: 530\n",
      "loss: tensor(18.4107, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.265\n",
      "pnl: 0\n",
      "inv reward: 0.265\n",
      "inventors: 530\n",
      "loss: tensor(12.6510, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3975\n",
      "pnl: 0\n",
      "inv reward: 0.3975\n",
      "inventors: 530\n",
      "loss: tensor(12.9225, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 530\n",
      "loss: tensor(12.0140, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 530\n",
      "loss: tensor(14.3664, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.8150000000000001\n",
      "pnl: 0.02\n",
      "inv reward: 0.795\n",
      "inventors: 430\n",
      "loss: tensor(0.1727, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 430\n",
      "loss: tensor(32.9165, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5575\n",
      "pnl: 0.02\n",
      "inv reward: 0.5375\n",
      "inventors: 330\n",
      "loss: tensor(0.0121, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.18\n",
      "pnl: 0.015\n",
      "inv reward: 0.165\n",
      "inventors: 430\n",
      "loss: tensor(0.4001, grad_fn=<SmoothL1LossBackward>)\n",
      "Epsiode 0 | step 600 | reward -41.18064999999997 | loss 3311.914386349794\n",
      "reward: -0.43\n",
      "pnl: 0\n",
      "inv reward: -0.43\n",
      "inventors: 430\n",
      "loss: tensor(0.0568, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 430\n",
      "loss: tensor(7.1802, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.21695\n",
      "pnl: 0.00195\n",
      "inv reward: 0.215\n",
      "inventors: 417\n",
      "loss: tensor(33.7427, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 417\n",
      "loss: tensor(38.2985, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 417\n",
      "loss: tensor(23.5220, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.18589999999999998\n",
      "pnl: 0.022600000000000002\n",
      "inv reward: -0.2085\n",
      "inventors: 517\n",
      "loss: tensor(20.8779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7755\n",
      "pnl: 0\n",
      "inv reward: -0.7755\n",
      "inventors: 517\n",
      "loss: tensor(0.2278, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2585\n",
      "pnl: 0\n",
      "inv reward: 0.2585\n",
      "inventors: 517\n",
      "loss: tensor(0.0438, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.266\n",
      "pnl: 0.0075\n",
      "inv reward: 0.2585\n",
      "inventors: 467\n",
      "loss: tensor(0.0684, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.442\n",
      "pnl: 0.025\n",
      "inv reward: -0.467\n",
      "inventors: 567\n",
      "loss: tensor(29.6336, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.26849999999999996\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: -0.2835\n",
      "inventors: 667\n",
      "loss: tensor(1.8250, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.025\n",
      "pnl: 0.025\n",
      "inv reward: 0.0\n",
      "inventors: 767\n",
      "loss: tensor(7.8972, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.31725\n",
      "pnl: 0.025\n",
      "inv reward: -1.34225\n",
      "inventors: 867\n",
      "loss: tensor(34.5128, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.61025\n",
      "pnl: 0.04\n",
      "inv reward: -0.65025\n",
      "inventors: 967\n",
      "loss: tensor(3.3946, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.901\n",
      "pnl: 0\n",
      "inv reward: -2.901\n",
      "inventors: 967\n",
      "loss: tensor(17.3999, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.4155\n",
      "pnl: 0.035\n",
      "inv reward: -1.4505\n",
      "inventors: 1067\n",
      "loss: tensor(2.7472, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5335\n",
      "pnl: 0\n",
      "inv reward: 0.5335\n",
      "inventors: 1067\n",
      "loss: tensor(38.9674, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.6005\n",
      "pnl: 0\n",
      "inv reward: 1.6005\n",
      "inventors: 1067\n",
      "loss: tensor(26.9326, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5335\n",
      "pnl: 0\n",
      "inv reward: -0.5335\n",
      "inventors: 1067\n",
      "loss: tensor(26.8402, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1067\n",
      "loss: tensor(30.1431, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1067\n",
      "loss: tensor(34.4933, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.067\n",
      "pnl: 0\n",
      "inv reward: -1.067\n",
      "inventors: 1067\n",
      "loss: tensor(9.9699, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1067\n",
      "loss: tensor(30.3364, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.067\n",
      "pnl: 0\n",
      "inv reward: 1.067\n",
      "inventors: 1067\n",
      "loss: tensor(19.3273, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.5335\n",
      "pnl: 0\n",
      "inv reward: -0.5335\n",
      "inventors: 1067\n",
      "loss: tensor(4.0458, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 1067\n",
      "loss: tensor(13.9372, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.5485\n",
      "pnl: 0.015\n",
      "inv reward: 0.5335\n",
      "inventors: 967\n",
      "loss: tensor(3.2366, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 967\n",
      "loss: tensor(36.6064, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 967\n",
      "loss: tensor(14.6974, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4985\n",
      "pnl: 0.015\n",
      "inv reward: 0.4835\n",
      "inventors: 867\n",
      "loss: tensor(38.9416, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4341\n",
      "pnl: 0.0006\n",
      "inv reward: 0.4335\n",
      "inventors: 863\n",
      "loss: tensor(0.0263, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0048000000000000004\n",
      "pnl: 0.0048000000000000004\n",
      "inv reward: 0.0\n",
      "inventors: 767\n",
      "loss: tensor(0.3235, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3835\n",
      "pnl: 0\n",
      "inv reward: 0.3835\n",
      "inventors: 767\n",
      "loss: tensor(0.4190, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 767\n",
      "loss: tensor(13.4982, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.782\n",
      "pnl: 0.015\n",
      "inv reward: 0.767\n",
      "inventors: 667\n",
      "loss: tensor(4.7635, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 667\n",
      "loss: tensor(0.3680, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 567\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 2.268\n",
      "pnl: 0\n",
      "inv reward: 2.268\n",
      "inventors: 567\n",
      "loss: tensor(2.2062, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 567\n",
      "loss: tensor(14.1918, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 567\n",
      "loss: tensor(15.1059, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 567\n",
      "loss: tensor(33.5420, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 567\n",
      "loss: tensor(4.5247, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.42525\n",
      "pnl: 0\n",
      "inv reward: 0.42525\n",
      "inventors: 567\n",
      "loss: tensor(14.2961, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.42525\n",
      "pnl: 0\n",
      "inv reward: -0.42525\n",
      "inventors: 567\n",
      "loss: tensor(30.4304, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.45025000000000004\n",
      "pnl: 0.025\n",
      "inv reward: 0.42525\n",
      "inventors: 467\n",
      "loss: tensor(0.9700, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.57845\n",
      "pnl: -0.0053\n",
      "inv reward: 0.58375\n",
      "inventors: 420\n",
      "loss: tensor(39.9329, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.05\n",
      "pnl: 0\n",
      "inv reward: 1.05\n",
      "inventors: 420\n",
      "loss: tensor(6.5945, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.665\n",
      "pnl: 0.034999999999999996\n",
      "inv reward: 0.63\n",
      "inventors: 320\n",
      "loss: tensor(9.1036, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.995\n",
      "pnl: 0.035\n",
      "inv reward: 0.96\n",
      "inventors: 220\n",
      "loss: tensor(22.3440, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.35500000000000004\n",
      "pnl: 0.025\n",
      "inv reward: 0.33\n",
      "inventors: 120\n",
      "loss: tensor(9.8035, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.09\n",
      "pnl: 0\n",
      "inv reward: 0.09\n",
      "inventors: 120\n",
      "loss: tensor(8.9721, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.22999999999999998\n",
      "pnl: 0.02\n",
      "inv reward: 0.21\n",
      "inventors: 20\n",
      "loss: tensor(7.8859, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.07\n",
      "pnl: 0\n",
      "inv reward: 0.07\n",
      "inventors: 20\n",
      "loss: tensor(0.7475, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.05500000000000001\n",
      "pnl: 0.035\n",
      "inv reward: 0.02\n",
      "inventors: -80\n",
      "loss: tensor(7.4204, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.24\n",
      "pnl: 0\n",
      "inv reward: -0.24\n",
      "inventors: -80\n",
      "loss: tensor(44.0884, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.14500000000000002\n",
      "pnl: 0.055\n",
      "inv reward: -0.2\n",
      "inventors: -180\n",
      "loss: tensor(5.5096, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -180\n",
      "loss: tensor(21.6878, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.225\n",
      "pnl: 0\n",
      "inv reward: -0.225\n",
      "inventors: -180\n",
      "loss: tensor(23.7836, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.945\n",
      "pnl: 0\n",
      "inv reward: -0.945\n",
      "inventors: -180\n",
      "loss: tensor(0.0004, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.765\n",
      "pnl: 0\n",
      "inv reward: -0.765\n",
      "inventors: -180\n",
      "loss: tensor(0.0003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.245\n",
      "pnl: 0.02\n",
      "inv reward: 0.225\n",
      "inventors: -80\n",
      "loss: tensor(2.2505, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.1297\n",
      "pnl: 0.0297\n",
      "inv reward: 0.1\n",
      "inventors: -14\n",
      "loss: tensor(29.4909, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0175\n",
      "pnl: 0\n",
      "inv reward: -0.0175\n",
      "inventors: -14\n",
      "loss: tensor(38.7060, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -14\n",
      "loss: tensor(47.5819, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0025000000000000005\n",
      "pnl: 0.0045\n",
      "inv reward: -0.007\n",
      "inventors: -44\n",
      "loss: tensor(0.2205, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0035\n",
      "pnl: 0.0035\n",
      "inv reward: -0.0\n",
      "inventors: -114\n",
      "loss: tensor(0.0772, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.013500000000000002\n",
      "pnl: 0.015\n",
      "inv reward: -0.0285\n",
      "inventors: -14\n",
      "loss: tensor(40.6981, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0735\n",
      "pnl: 0\n",
      "inv reward: 0.0735\n",
      "inventors: -14\n",
      "loss: tensor(0.7160, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.021\n",
      "pnl: 0\n",
      "inv reward: 0.021\n",
      "inventors: -14\n",
      "loss: tensor(12.6062, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -14\n",
      "loss: tensor(6.5546, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: -0.0\n",
      "inventors: -14\n",
      "loss: tensor(26.1344, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0425\n",
      "pnl: 0.025\n",
      "inv reward: 0.0175\n",
      "inventors: 86\n",
      "loss: tensor(14.1536, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.0009\n",
      "pnl: -0.0009\n",
      "inv reward: 0.0\n",
      "inventors: 77\n",
      "loss: tensor(2.6214, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.03945\n",
      "pnl: 0.0183\n",
      "inv reward: -0.05775\n",
      "inventors: 138\n",
      "loss: tensor(32.9233, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.12300000000000001\n",
      "pnl: 0.015\n",
      "inv reward: -0.138\n",
      "inventors: 238\n",
      "loss: tensor(2.2945, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 238\n",
      "loss: tensor(4.2889, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 238\n",
      "loss: tensor(6.4454, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3558\n",
      "pnl: -0.0012\n",
      "inv reward: 0.357\n",
      "inventors: 214\n",
      "loss: tensor(8.2167, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1605\n",
      "pnl: 0\n",
      "inv reward: -0.1605\n",
      "inventors: 214\n",
      "loss: tensor(0.0510, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0535\n",
      "pnl: 0\n",
      "inv reward: 0.0535\n",
      "inventors: 214\n",
      "loss: tensor(19.0761, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.107\n",
      "pnl: 0\n",
      "inv reward: 0.107\n",
      "inventors: 214\n",
      "loss: tensor(17.1996, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.107\n",
      "pnl: 0\n",
      "inv reward: 0.107\n",
      "inventors: 214\n",
      "loss: tensor(0.1432, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 214\n",
      "loss: tensor(0.3306, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0018\n",
      "pnl: 0.0018\n",
      "inv reward: 0.0\n",
      "inventors: 226\n",
      "loss: tensor(0.1279, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.18450000000000003\n",
      "pnl: 0.015000000000000001\n",
      "inv reward: 0.1695\n",
      "inventors: 126\n",
      "loss: tensor(0.2718, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0945\n",
      "pnl: 0\n",
      "inv reward: 0.0945\n",
      "inventors: 126\n",
      "loss: tensor(0.9852, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.101\n",
      "pnl: 0.025\n",
      "inv reward: -0.126\n",
      "inventors: 226\n",
      "loss: tensor(14.5783, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.41700000000000004\n",
      "pnl: 0.035\n",
      "inv reward: -0.452\n",
      "inventors: 326\n",
      "loss: tensor(6.4647, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0147\n",
      "pnl: 0.0147\n",
      "inv reward: 0.0\n",
      "inventors: 424\n",
      "loss: tensor(7.5915, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.2117\n",
      "pnl: 0.0003\n",
      "inv reward: -0.212\n",
      "inventors: 426\n",
      "loss: tensor(31.3668, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 426\n",
      "loss: tensor(1.1074, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.213\n",
      "pnl: 0\n",
      "inv reward: -0.213\n",
      "inventors: 426\n",
      "loss: tensor(16.3376, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.213\n",
      "pnl: 0\n",
      "inv reward: 0.213\n",
      "inventors: 426\n",
      "loss: tensor(15.4411, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.198\n",
      "pnl: 0.015\n",
      "inv reward: -0.213\n",
      "inventors: 526\n",
      "loss: tensor(0.4305, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1315\n",
      "pnl: 0\n",
      "inv reward: -0.1315\n",
      "inventors: 526\n",
      "loss: tensor(1.3268, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.1315\n",
      "pnl: 0\n",
      "inv reward: -0.1315\n",
      "inventors: 526\n",
      "loss: tensor(0.7896, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 526\n",
      "loss: tensor(44.2839, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 526\n",
      "loss: tensor(30.6779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 526\n",
      "loss: tensor(8.3014, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.012\n",
      "pnl: 0.012\n",
      "inv reward: 0.0\n",
      "inventors: 446\n",
      "loss: tensor(8.7416, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.003\n",
      "pnl: 0.003\n",
      "inv reward: 0.0\n",
      "inventors: 426\n",
      "loss: tensor(2.0097, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.22799999999999998\n",
      "pnl: 0.015\n",
      "inv reward: 0.213\n",
      "inventors: 326\n",
      "loss: tensor(24.1647, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.163\n",
      "pnl: 0\n",
      "inv reward: 0.163\n",
      "inventors: 326\n",
      "loss: tensor(0.0449, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.163\n",
      "pnl: 0\n",
      "inv reward: 0.163\n",
      "inventors: 326\n",
      "loss: tensor(47.0595, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 326\n",
      "loss: tensor(11.2390, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.311\n",
      "pnl: 0.015\n",
      "inv reward: -0.326\n",
      "inventors: 426\n",
      "loss: tensor(11.0749, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.01095\n",
      "pnl: 0.01095\n",
      "inv reward: 0.0\n",
      "inventors: 499\n",
      "loss: tensor(5.8733, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2495\n",
      "pnl: 0\n",
      "inv reward: 0.2495\n",
      "inventors: 499\n",
      "loss: tensor(45.2102, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00675\n",
      "pnl: 0.00675\n",
      "inv reward: 0.0\n",
      "inventors: 526\n",
      "loss: tensor(0.3524, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.263\n",
      "pnl: 0\n",
      "inv reward: -0.263\n",
      "inventors: 526\n",
      "loss: tensor(0.3779, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.24445\n",
      "pnl: -0.01855\n",
      "inv reward: 0.263\n",
      "inventors: 473\n",
      "loss: tensor(12.2885, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 473\n",
      "loss: tensor(1.9627, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.22149999999999997\n",
      "pnl: 0.015\n",
      "inv reward: -0.2365\n",
      "inventors: 573\n",
      "loss: tensor(0.0059, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 573\n",
      "loss: tensor(26.0369, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.30855\n",
      "pnl: 0.02205\n",
      "inv reward: 0.2865\n",
      "inventors: 636\n",
      "loss: tensor(26.4573, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 636\n",
      "loss: tensor(2.4680, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 636\n",
      "loss: tensor(0.0073, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0066\n",
      "pnl: 0.0066\n",
      "inv reward: 0.0\n",
      "inventors: 592\n",
      "loss: tensor(2.2802, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.28099999999999997\n",
      "pnl: 0.015\n",
      "inv reward: -0.296\n",
      "inventors: 692\n",
      "loss: tensor(1.2651, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 692\n",
      "loss: tensor(0.1717, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 692\n",
      "loss: tensor(51.6858, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 692\n",
      "loss: tensor(7.5147, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 692\n",
      "loss: tensor(31.8030, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.6774\n",
      "pnl: 0.0146\n",
      "inv reward: -0.692\n",
      "inventors: 616\n",
      "loss: tensor(0.0091, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0046\n",
      "pnl: 0.0046\n",
      "inv reward: 0.0\n",
      "inventors: 708\n",
      "loss: tensor(1.0744, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.57485\n",
      "pnl: 0.01815\n",
      "inv reward: -1.593\n",
      "inventors: 741\n",
      "loss: tensor(14.9399, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.15525\n",
      "pnl: 0.03\n",
      "inv reward: -0.18525\n",
      "inventors: 641\n",
      "loss: tensor(16.1882, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.6375\n",
      "pnl: 0.035\n",
      "inv reward: 1.6025\n",
      "inventors: 541\n",
      "loss: tensor(1.1435, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.40575\n",
      "pnl: 0\n",
      "inv reward: 0.40575\n",
      "inventors: 541\n",
      "loss: tensor(0.4083, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.7915\n",
      "pnl: 0.02\n",
      "inv reward: -0.8115\n",
      "inventors: 641\n",
      "loss: tensor(32.8663, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.80125\n",
      "pnl: 0\n",
      "inv reward: -0.80125\n",
      "inventors: 641\n",
      "loss: tensor(36.3701, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 641\n",
      "loss: tensor(10.8239, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 641\n",
      "loss: tensor(11.8983, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.015\n",
      "pnl: 0.015\n",
      "inv reward: 0.0\n",
      "inventors: 541\n",
      "loss: tensor(3.1044, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.2705\n",
      "pnl: 0\n",
      "inv reward: 0.2705\n",
      "inventors: 541\n",
      "loss: tensor(15.3730, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00105\n",
      "pnl: 0.00105\n",
      "inv reward: 0.0\n",
      "inventors: 548\n",
      "loss: tensor(18.0961, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.685\n",
      "pnl: 0\n",
      "inv reward: -0.685\n",
      "inventors: 548\n",
      "loss: tensor(29.3006, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.137\n",
      "pnl: 0\n",
      "inv reward: -0.137\n",
      "inventors: 548\n",
      "loss: tensor(23.5003, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.274\n",
      "pnl: 0\n",
      "inv reward: -0.274\n",
      "inventors: 548\n",
      "loss: tensor(42.8862, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.822\n",
      "pnl: 0\n",
      "inv reward: -0.822\n",
      "inventors: 548\n",
      "loss: tensor(17.0569, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 548\n",
      "loss: tensor(0.5701, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.274\n",
      "pnl: 0\n",
      "inv reward: 0.274\n",
      "inventors: 548\n",
      "loss: tensor(0.0016, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.523\n",
      "pnl: 0.025\n",
      "inv reward: -0.548\n",
      "inventors: 648\n",
      "loss: tensor(0.2533, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 648\n",
      "loss: tensor(0.1888, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.62\n",
      "pnl: 0\n",
      "inv reward: -1.62\n",
      "inventors: 648\n",
      "loss: tensor(2.0231, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.633\n",
      "pnl: 0.015\n",
      "inv reward: -0.648\n",
      "inventors: 748\n",
      "loss: tensor(35.4004, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.374\n",
      "pnl: 0\n",
      "inv reward: -0.374\n",
      "inventors: 748\n",
      "loss: tensor(33.4342, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.935\n",
      "pnl: 0\n",
      "inv reward: -0.935\n",
      "inventors: 748\n",
      "loss: tensor(1.6051, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.935\n",
      "pnl: 0\n",
      "inv reward: 0.935\n",
      "inventors: 748\n",
      "loss: tensor(0.4678, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.0870000000000002\n",
      "pnl: 0.035\n",
      "inv reward: -1.122\n",
      "inventors: 848\n",
      "loss: tensor(0.0011, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 1.297\n",
      "pnl: 0.025\n",
      "inv reward: 1.272\n",
      "inventors: 748\n",
      "loss: tensor(0.0361, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(0.0657, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(0.9903, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(0.0007, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.374\n",
      "pnl: 0\n",
      "inv reward: -0.374\n",
      "inventors: 748\n",
      "loss: tensor(2.9043, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(16.0076, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(16.9731, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.187\n",
      "pnl: 0\n",
      "inv reward: 0.187\n",
      "inventors: 748\n",
      "loss: tensor(3.2402, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(0.6132, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.187\n",
      "pnl: 0\n",
      "inv reward: -0.187\n",
      "inventors: 748\n",
      "loss: tensor(0.5778, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 748\n",
      "loss: tensor(32.1344, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.00465\n",
      "pnl: 0.00465\n",
      "inv reward: 0.0\n",
      "inventors: 779\n",
      "loss: tensor(6.0732, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.56925\n",
      "pnl: 0.015\n",
      "inv reward: -0.58425\n",
      "inventors: 879\n",
      "loss: tensor(10.5522, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -0.879\n",
      "pnl: 0\n",
      "inv reward: -0.879\n",
      "inventors: 879\n",
      "loss: tensor(34.4542, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.4595\n",
      "pnl: 0.02\n",
      "inv reward: 0.4395\n",
      "inventors: 779\n",
      "loss: tensor(0.6388, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.17915\n",
      "pnl: -0.0156\n",
      "inv reward: 0.19475\n",
      "inventors: 701\n",
      "loss: tensor(8.1843, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 701\n",
      "loss: tensor(24.1232, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 701\n",
      "loss: tensor(22.5921, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.3505\n",
      "pnl: 0\n",
      "inv reward: 0.3505\n",
      "inventors: 701\n",
      "loss: tensor(0.0505, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 701\n",
      "loss: tensor(8.8044, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 701\n",
      "loss: tensor(6.8841, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.21175\n",
      "pnl: 0.015\n",
      "inv reward: -1.22675\n",
      "inventors: 801\n",
      "loss: tensor(0.1588, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.00125\n",
      "pnl: 0\n",
      "inv reward: -1.00125\n",
      "inventors: 801\n",
      "loss: tensor(40.9367, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 801\n",
      "loss: tensor(1.1927, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -2.338\n",
      "pnl: 0.065\n",
      "inv reward: -2.403\n",
      "inventors: 901\n",
      "loss: tensor(7.2518, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.802\n",
      "pnl: 0\n",
      "inv reward: -1.802\n",
      "inventors: 901\n",
      "loss: tensor(0.4251, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.901\n",
      "pnl: 0\n",
      "inv reward: 0.901\n",
      "inventors: 901\n",
      "loss: tensor(0.4682, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: -1.12625\n",
      "pnl: 0\n",
      "inv reward: -1.12625\n",
      "inventors: 901\n",
      "loss: tensor(4.1803, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 901\n",
      "loss: tensor(0.1664, grad_fn=<SmoothL1LossBackward>)\n",
      "reward: 0.0\n",
      "pnl: 0\n",
      "inv reward: 0.0\n",
      "inventors: 901\n",
      "loss: tensor(45.4795, grad_fn=<SmoothL1LossBackward>)\n",
      "Epsiode 0 | step 780 | reward -53.991300000000045 | loss 5662.4618432252955\n",
      "100%|██████████| 1/1 [01:00<00:00, 60.62s/it]\n",
      "tensor([[ 1.5174, -0.0286, -0.7599, -0.5414, -0.1713, -0.0184,  0.0882,  1.3771,\n",
      "          0.0600, -0.5538, -0.5160,  0.2415,  0.0163,  0.3845, -0.0231,  0.7186,\n",
      "         -0.9161, -1.0805,  0.6220,  0.1652,  0.7449, -0.4434, -0.0474,  0.7891,\n",
      "          0.9215, -0.9178,  0.0378,  0.0713, -0.3990,  0.0881,  0.5189,  0.9102,\n",
      "         -0.5964,  0.3496,  0.1727, -0.2999, -0.3107,  0.5754,  0.0400,  1.1375,\n",
      "          0.3992,  0.1354,  0.0650, -0.7635, -0.1727, -0.5085, -0.3793,  0.7478,\n",
      "         -0.1958,  0.0884, -0.7080,  0.3809,  0.1670, -0.0960,  0.0626,  0.9657]])\n"
     ]
    }
   ],
   "source": [
    "episodes = 250\n",
    "lr = 0.0005\n",
    "window_length = 30\n",
    "eps = 0.9\n",
    "eps_decay = utils.linear_decay(epochs=170000, start=eps, end=0.001)\n",
    "\n",
    "sigpolicy = SigPolicy(env, 3)\n",
    "sigpolicy.initialize_parameters(zero_bias=True)\n",
    "print(sigpolicy.linear.weight.data)\n",
    "\n",
    "results = train(env, \n",
    "                sigpolicy, \n",
    "                episodes, \n",
    "                learning_rate=lr, \n",
    "                epsilon=eps,\n",
    "                epsilon_decay=eps_decay,\n",
    "                window_length=window_length, \n",
    "                printing=False)\n",
    "\n",
    "print(sigpolicy.linear.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[\"actions\"][15])\n",
    "#plt.plot([reward if reward < 50000 else 500 for reward in results[\"rewards\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
